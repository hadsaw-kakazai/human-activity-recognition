{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a5b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Seed\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb431496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6bbedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108170, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Pid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>S1_Ax</th>\n",
       "      <th>S1_Ay</th>\n",
       "      <th>S1_Az</th>\n",
       "      <th>S1_Gx</th>\n",
       "      <th>S1_Gy</th>\n",
       "      <th>S1_Gz</th>\n",
       "      <th>S2_Ax</th>\n",
       "      <th>...</th>\n",
       "      <th>S2_Gx</th>\n",
       "      <th>S2_Gy</th>\n",
       "      <th>S2_Gz</th>\n",
       "      <th>S3_Ax</th>\n",
       "      <th>S3_Ay</th>\n",
       "      <th>S3_Az</th>\n",
       "      <th>S3_Gx</th>\n",
       "      <th>S3_Gy</th>\n",
       "      <th>S3_Gz</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P1_BS</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-84.23</td>\n",
       "      <td>-994.63</td>\n",
       "      <td>8.06</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>1.65</td>\n",
       "      <td>311.28</td>\n",
       "      <td>...</td>\n",
       "      <td>2.08</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>-68.12</td>\n",
       "      <td>-970.46</td>\n",
       "      <td>150.15</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Downstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P1_BS</td>\n",
       "      <td>3.01</td>\n",
       "      <td>-86.43</td>\n",
       "      <td>-1004.15</td>\n",
       "      <td>16.85</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-3.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>301.76</td>\n",
       "      <td>...</td>\n",
       "      <td>6.77</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>-73.24</td>\n",
       "      <td>-978.52</td>\n",
       "      <td>140.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Downstairs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Pid  timestamp  S1_Ax    S1_Ay  S1_Az  S1_Gx  S1_Gy  S1_Gz  \\\n",
       "0           0  P1_BS       3.00 -84.23  -994.63   8.06  -0.37  -2.62   1.65   \n",
       "1           1  P1_BS       3.01 -86.43 -1004.15  16.85  -0.18  -3.17   0.85   \n",
       "\n",
       "    S2_Ax  ...  S2_Gx  S2_Gy  S2_Gz  S3_Ax   S3_Ay   S3_Az  S3_Gx  S3_Gy  \\\n",
       "0  311.28  ...   2.08  -3.23  -4.33 -68.12 -970.46  150.15   1.83   0.24   \n",
       "1  301.76  ...   6.77   3.05  -3.78 -73.24 -978.52  140.62   0.55  -0.24   \n",
       "\n",
       "   S3_Gz       Label  \n",
       "0   0.61  Downstairs  \n",
       "1   0.31  Downstairs  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('belt_sensor_all.csv')\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7774df8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pid\n",
       "P1_BS            12278\n",
       "P2_BS            13016\n",
       "P3_BS            13016\n",
       "P4_BS            12946\n",
       "P5_BS            13016\n",
       "p10_all_BS123     8825\n",
       "p11_all_BS123     8598\n",
       "p6_all_BS123      8825\n",
       "p7_all_BS123      8825\n",
       "p8_all_BS123      8825\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Pid').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea597caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Low Pass filter \n",
    "from scipy import signal\n",
    "def butter_lowpass(cutoff, nyq_freq, order=4):\n",
    "    normal_cutoff = float(cutoff) / nyq_freq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='lowpass')\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_freq, nyq_freq, order=4):\n",
    "    b, a = butter_lowpass(cutoff_freq, nyq_freq, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff313b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low pass filter\n",
    "lowpass_filtred=[]\n",
    "dfm=df[['S1_Ax', 'S1_Ay', 'S1_Az', 'S1_Gx', 'S1_Gy','S1_Gz', 'S2_Ax', 'S2_Ay', 'S2_Az', 'S2_Gx', 'S2_Gy', 'S2_Gz', 'S3_Ax',\n",
    "       'S3_Ay', 'S3_Az', 'S3_Gx', 'S3_Gy', 'S3_Gz']]\n",
    "for column in dfm.columns:# iterate over each column in raw_df\n",
    "    cutoff_frequency = 15.0\n",
    "    sample_rate=100\n",
    "    t_signal=np.array(dfm[column]) #copie the signal values in 1D numpy array\n",
    "    y = butter_lowpass_filter(t_signal,cutoff_frequency,sample_rate/2) \n",
    "    lowpass_filtred.append(y)\n",
    "lowpass=pd.DataFrame(lowpass_filtred)\n",
    "lowpass=lowpass.T\n",
    "lowpass.columns=['S1_Ax', 'S1_Ay', 'S1_Az', 'S1_Gx', 'S1_Gy','S1_Gz', 'S2_Ax', 'S2_Ay', 'S2_Az', 'S2_Gx', 'S2_Gy', 'S2_Gz', 'S3_Ax',\n",
    "       'S3_Ay', 'S3_Az', 'S3_Gx', 'S3_Gy', 'S3_Gz']\n",
    "df1=df[['Pid','timestamp']]\n",
    "df_filtred=pd.concat([df1,lowpass],axis=1)\n",
    "df_filtred['Label']=df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff599e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Upstairs      29345\n",
       "Downstairs    25030\n",
       "Walking       19440\n",
       "Standing      12180\n",
       "Sitting       11265\n",
       "Laying        10910\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtred['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb80b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      " Upstairs      29345\n",
      "Downstairs    25030\n",
      "Walking       19440\n",
      "Standing      12180\n",
      "Sitting       11265\n",
      "Laying        10910\n",
      "Name: Label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAGJCAYAAADrDRu+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqHElEQVR4nO3deZwlVX338c8sMIAsKiAIAirCT2WIwASCCkIiieIjEReMIItKVFD0QTBoDCL6iEHEDQFBRWURjEREQmQJCiIREEcBB8NPQIERNOybwAAz8/xxTsulp0/PvT3dfXu6P+/Xa15zb52quqeq76361qnlTFu8eDGSJElDmd7vCkiSpInLoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDApSFRGHR8Rp/a5Hp4g4LyL2GaV5bR8R2fH+5ojYaTTmXed3XUTsOFrzGy0R8fqImB8RD0XElv2uz3BG+2/S+IwJ+XfSxDWz3xWQxlNE7AEcBLwQeBC4GjgiMy/rQ10WAw8Di4EFtS5fycx/GxgnM3fuYV6bZOaNrXEy8ydALEudOz7vm8DvM/PQjvlvNhrzHuKzLgG2BZ4AFgLXAO/NzF91OYujgQMy8/tjUb9Odb3sATxG+bv+BjgoM3881p/drbH6O2nyskVBU0ZEHAR8AfgUsA6wIXA88Lo+VuslmbkqZQf+TeDYiPjYaH9IRCzvBwUH1PX0TOAS4NQept0IuG4kHxoRM0Yw2VG1rqsDXwbOGuF8pAlhed94SF2JiDWATwBvz8yzOor+o/4bapozge2BlSlHsftn5nW17DWUI9UNgAeAz2fm0RGxFmWHvx2wiLKD2iEzFw1Xv8y8Czg1Ih4BTouIYzPz7no0fVpmfi0iXgCcBGwBPA78MDP/ISIurbO5prYs7Av8L3Aa8CXgA8B/RcRJdV7P6fjorSPiGODZwNl1GR+NiLcB/5iZ23Wsj8XAJsDfAG8FFkfEgcDFmblLRNxcp7koImYBnwbeXCf/DvChzFxQm71PAz4PfIjSSvCRzPzGcOuorqeFEfFt4MMd9ZoOHAK8E3g68ENgP+BPwN3AjLpu/piZG0fEiyg78C2A24B/zsxz6ry+CTxCCRc7AK+LiF/X9fgK4CHK3/qYLuq6OCJOB75KCaa3R8TG9f1LKC0OF1BaR+4bPH1EbAN8EXhRrdN3Ka0Tj9XyxcD+wMHA2sC3KIFqcS1/J6X17DnAfGDPzPzFoL/T4cCLgUeB1wO3Avtk5s/rPLaifOdeAJxP+U7f0NmSpMnPFgVNFS8FVgK+18M051F2jM8CfkHZEA84CXh3Zq4GzAZ+VIcfDPyesuFeB/gIZYfQre9TAvw2Q5T9P+BC4BmUjf+XADLzFbX8JZm5asepi3UpR+AbAe9qfN5bgVcBGwObAkvdAWTmVyjr4qj6ebsMMdq/UE4XbEHZKW4zaN7rAmsA61OCzXER8YylfXZErFjrfEXH4PcBu1J27OsB9wLHZeaCemQPZd1sHBErUILhhZS/6/uAb0VE5ymZPYAjgNWAn9bxr6l1fSVwYES8qou6zgD2Bn5HCW4A04B/rfV8ESVoHt6YxUJKyFuL8v19JfCeQeO8Ftga+AtKKHtV/ezd6nz3prRs/D0lNA3l74FvU0LWOcCxdR4rUn4v36R8j86ghAlNMbYoaKpYE7grM5/odoLM/PrA63rkdW9ErJGZ91OO6F8cEddk5r2UnRN1+LOBjer1Aj/ppZKZ+XhE3EXZMA/2OGWnv15m/h5Y2nUVi4CPZeaCugxDjXNsZs6v5UdQwsdoHC2+FXhfZt5R5/1x4ETgo7X8ceAT9e/xg4h4iHL65YqhZgYcExFHU1p3HgXe0FG2H+VI+vf1sw4Hbo2IvYb4e28LrAocWVt5fhQR5wK78+QO+/uZ+d91XpsDa2fmJ2rZbyPiq8BbKK0BQ/lgRBwAzKIEg30zcyFA/U4MXEdyZ0R8DhjyVFNmzu14e3NEnEgJQ1/oGH5kbY24LyIupgSz84F/pAS5q+p4zWtXgMsy8wd1eU8FDqzDt6XsI46prRRnRcTPhpmPJimDgqaKu4G1ImJmN2GhHg0eAexGaR0YOHWwFnA/8EbKDvXIiLgW+HBmXg58hrLDubDumL+SmUd2W8l6xLs2cM8QxYdQWhV+FhH3Ap/tDDNDuDMzH13KR87veH0L5Uh3NKxX59ea992D/g4PU3bgLe+vp1+mAy8HzomIHTLzWkp4+l5EdJ7eWUhp0bltiHrNH3Qq6BZKa8GAznWyEbBeRNzXMWwGwwfAozPz0IiYBmxG+S7ck5nnRcQ6lNMJ21NaLKbzZMh8iojYFPgc8JfAKpTt9dxBo/2x43XnOtwAuGmYOg43j5XqNS3rAbcNnMqo5qMpx1MPmioup9xZsGuX4+9BuchxJ0oT+XPr8GkAmXlVZr6O0nx9NuUcPJn5YGYenJnPpzTpHhQRr+yhnq+jXN2/xJFbZv4xM9+ZmesB7waOr9cttHRzymODjtcbArfX13+i7JwAiIh1e5z37ZSd7FDzHrHMXFTv3rgR+Ls6eD6wc2Y+vePfSpk5OCQM1GuDGjg669Y57uAd4+8GzXu1zHxNF3VdnJnzgP8G/k8d/Kk6/80zc3VgT+p3aghfBq6n3M2yOuU0VmvcweZTTictiz8A69fAM2CD1siavGxR0JSQmfdHxGGUc+FPUM5RP04JAn+dmYcMmmQ1SrC4m7LD/NRAQT13uxtwbp3vA9QWh4h4LWXjfhOl5WEhT7ZGNEXEM4GdKUeQn87MJc4n1/POl9cm9nspO5yBef8v8HyGb2Ieyntr0/vDlOsKBq5vuAbYLCK2qMtz+KDpBj6v5Qzg0Ii4qtbzMMoFjMssIl5KuQBv4E6GE4AjImKfzLwlItYGXta4HfJKyrIeEhGfpbRO7EI5zz+UnwEPRsSHgGMotz2+CFi5o1l/uLq+kHJh68Cpi9Uo34v7I2J94J+GmXw1yoWyD9X57A/cubTPrL4GfC4iLqNcX7Mx8Hhm3jL8ZE9xOeX7e0BEfJkSdrah3HWiKcQWBU0ZmflZylXgh1I2uPOBAygtAoOdQmmSvg34NUueO9+Lct74Aco58rfW4ZsAF1Gujr8cOD4zLx6mWtfU8/M3Us4rfyAzD2uMuzVwZR3/HOD/ZuZva9nhwMkRcV9EvLkx/VBOp4Sm31LCzScBMvM3lJ3bRcANLHk9xEmUazTui4izh5jvJ4GfA9cCv6LsrD7ZQ70GO7Y+MOkhyq2Rh2bmebXsi5T1cWFEPEj5W/3VUDOpdwzsQglld1Fuj907M69vjL+QcsHgFpSLEu+i7ITXGKauh9S6/omybr9BuT4D4OPAVpSw8J/AWUPPAoAPUlq2HqTcKfFvw4w7uN5nUk6dnV6nP5uhr3sZbh6PUa4F2Re4j9L6cS4lQGsKmbZ4cS8XZEuSpqqIuBI4oZtbWTV5eOpBkjSkiNgBSEpLylspt2Ge39dKadwZFCRJLUG5UPdplNNTb8rMP/S3ShpvnnqQJElNXswoSZKaPPUwyNy5c2dRri7/A+XWIEmSJrMZlCfKXjVnzpwl7moxKCxpa3p87K4kSZPA9gzxaHiDwpL+ALDpppuy4oor9rsukiSNqccee4zf/OY3UPd/gxkUlrQQYMUVV2TWrFn9roskSeNlyNPtXswoSZKaDAqSJKlp3E491OfBP4/Sic1DlL7qr65dqZ4MrEnpgGfvzLyhTjPqZZIkqXvj2aKwT2a+JDO3BI4Gvl6HnwAcl5mbAsfxZOcpY1UmSZK6NG4tCpl5f8fbNYBFEfEsSk9qf1uHn0HpJW5tSr/ro1qWmd120SpJkhjnaxQi4msRcSul+9N9gA2A22pXrgNdut5eh49FmSRJ6sG43h6Zmf8IEBF7AZ8BPjqen9+LefPm9bsKkiT1Xd86hYqIR4DnUrowXTMzF0bEDMrFh5tQTiH8ZjTLujn1MHfu3OcCv5s9e7bPUZAkTXoLFiwYODh+3pw5c24eXD4upx4iYtWI2KDj/S7APcAdwNXA7rVod+CXmXlnZo562dgsnSRJk9d4nXp4GnBmRDyN8uSne4BdMnNxROwHnBwRhwH3Ant3TDcWZZIkqUt9O/UwUXnqQZI0lUyIUw+SJGn5ZFCQJElNBgWpz55YuKjfVRg3U2lZpcnCbqalPps5YzrHn3ZZv6sxLt6z53b9roKkHtmiIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKlp5nh8SESsCZwKbAw8BtwAvDsz74yIxcCvgEV19L0y81d1ul2Az9R6zgXenpkPL0uZJEnq3ni1KCwGjsrMyMzNgZuAIzvKX5aZW9R/AyFhVeCrwC6Z+QLgQeCDy1ImSZJ6My5BITPvycxLOgZdAWy0lMl2Bn6emTfU9ycA/7CMZZIkqQfjcuqhU0RMB/YHzukYfElEzATOAw7PzAXAhsAtHePcCmxQX4+0bJk9vnAhK8yYMVqzm/Cm2vJKkp5q3IMC8CXgIeDY+n7DzJwfEatTrmP4KHBoH+r1FPPmzRty+Jw5czj4vFPGuTb989md92bu3Ln9rsakNmfOnH5XYVz5fZKWL+MaFCLiaGATyvUDiwAyc379/4GI+BpwUB39VuCvOybfEJi/jGVdmz17NrNmzep1sklpqu3INLb8PkkTy4IFC5oHxzCOt0dGxKeAOcCu9dQCEfGMiFi5vp4JvAm4uk5yPrB1RGxS3+8HfGcZyyRJUg/GJShExGbAPwPrAT+NiKsj4nvAC4ErI+Ia4FrgccqpBzLzQeBdwLkRcSOwBnD0spRJkqTejMuph8y8DpjWKP6LYab7PvD90SyTJEnd88mMkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaZo7Hh0TEmsCpwMbAY8ANwLsz886I2BY4EVgZuBnYMzPvqNONepkkSereeLUoLAaOyszIzM2Bm4AjI2I6cBrw3szcFLgUOBJgLMokSVJvxiUoZOY9mXlJx6ArgI2AOcCjmXlZHX4C8Ob6eizKJElSD8b9GoV6xL8/cA6wIXDLQFlm3gVMj4hnjlGZJEnqwbhcozDIl4CHgGOB1/fh87syb968IYfPmTNnnGvSf3Pnzu13FSa1qfad8vskLV/GNShExNHAJsAumbkoIm6lnIIYKF8LWJSZ94xFWS91nT17NrNmzRrZgk4yU21HprHl90maWBYsWNA8OIZxPPUQEZ+iXD+wa2YuqIPnAitHxHb1/X7AmWNYJkmSejBet0duBvwz8BvgpxEB8LvMfH1E7AWcGBErUW9lBKgtDqNaJkmSejMuQSEzrwOmNcp+Cmw+XmWSJKl7PplRkiQ1GRQ0ZhY/8Xi/qzBuptKySppa+nF7pKaIaTNX4I4vH9LvaoyLZ+1/VL+rIEljwhYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTV0HhYjYrTH8TaNXHUmSNJH00qJwUmP4V0ajIpIkaeKZubQRIuL59eX0iHgeMK2j+PnAo2NRMUmS1H9LDQrAjcBiSkC4aVDZH4HDR7lOkiRpglhqUMjM6QAR8ePM3GHsqyRJkiaKrq9RMCRIkjT1dHPqAYB6fcIRwBbAqp1lmbnh6FZLkiRNBF0HBeB0yjUKBwMPj011JEnSRNJLUNgMeHlmLhqrykiSpImll+coXApsOVYVkSRJE08vLQo3A+dHxPcot0X+WWYeNpqVkiRJE0MvQeFpwLnACsAGY1MdSZI0kXQdFDLz7WNZEUmSNPH0cnvk81tlmfnb0amOJEmaSHo59dD5KOcBi+v/M0atRpIkacLo5dTDU+6QiIh1gY8BPxntSkmSpImhl9sjnyIz/wgcCPzrqNVGkiRNKL2cehhKAKt0NWLE0cAbgecCm2fmvDr8ZkpX1QPdVX8oMy+oZdsCJwIrU27P3DMz71iWMkmS1L1eLmb8CU9ekwAlIGwGfKLLWZwNfJGhT1W8aSA4dHzedOA04G2ZeVlEHAocCbxjpGVd1lOSJFW9tCh8bdD7PwHXZOYN3UycmZcBRES3nzcHeHRgOuAESuvAO5ahTJIk9aCXixlPHsN6fCsipgGXAR/JzPuADYFbOj7/roiYHhHPHGlZZt4zhssgSdKk08uphxWAQ4G9gPWA24FTgSMy87FlqMP2mTk/ImYBXwCOBfZchvmNinnz5g05fM6cOeNck/6bO3fuiKabauvK9dSdka4nSf3Ry6mHo4BtgP0oR+wbAR8FVgc+MNIKZOb8+v+CiDgeOKcW3Vo/A4CIWAtYlJn3RMSIynqp1+zZs5k1a9ZIF2tSmWo7spFyPXXH9SRNLAsWLGgeHENvt0fuBvx9Zl6YxYXA64E3j7RyEfG0iFijvp4GvAW4uhbPBVaOiO3q+/2AM5exTJIk9aCXFoVpPQ5/iog4BngDsC5wUUTcDewCfDciZlCe7vhr4D0AmbkoIvYCToyIlai3OS5LmSRJ6k0vQeFM4D8i4uM8eVrgULo8Ws/M9wPvH6Joy2Gm+Smw+WiWSZKk7vUSFA6hBIPjKBcz3gacAXxyDOolSZImgKUGhYh4OeXahA8Bh9V/A2WfBrYCrhizGkqSpL7p5mLGjwCXNsouBv5l9KojSZImkm6CwhbA+Y2yiyhPQpQkSZNQN0FhdWDFRtkKwGqjVx1JkjSRdBMUrgf+rlH2d7VckiRNQt3c9fB5yjMJZgBn1+cUTAd2pdwBcdAY1k+SJPXRUoNCZp4eEesCJwOzIuIuYC1gAfCxzDxjjOsoSZL6pKvnKGTm5yLia8BLgTWBu4HLM/OBsaycJEnqr166mX4AuGAM6yJJkiaYXjqFkiRJU4xBQZIkNRkUJElSk0FBkiQ1GRQkSVKTQUGSJDUZFCRJUpNBQZIkNRkUJElSk0FBkiQ1GRQkSVKTQUGSJDUZFCRJUpNBQZIkNRkUJElT0uJFj/W7CuNqpMs7c5TrIUnScmHa9BW5/Wev6Xc1xs162/xgRNPZoiBJkpoMCpIkqcmgIEmSmgwKkiSpyaAgSZKaDAqSJKnJoCBJkpoMCpIkqcmgIGm5sOiJRf2uwriaasuricsnM0paLkyfOZ0bv/zjfldj3Lxg/x36XQUJsEVBkiQNw6AgSZKaDAqSNMksXPR4v6swbqbSsvaL1yhI0iQzY/oKnHrlu/pdjXGx1199pd9VmPRsUZAkSU0GBUmS1GRQkCRJTQYFSZLUNC4XM0bE0cAbgecCm2fmvDp8U+BkYE3gbmDvzLxhrMokSVJvxqtF4WzgFcAtg4afAByXmZsCxwEnjnGZJEnqwbi0KGTmZQAR8edhEfEsYCvgb+ugM4BjI2JtYNpol2XmnWOzdJIkTV79fI7CBsBtmbkQIDMXRsTtdfi0MSjrKSjMmzdvyOFz5szpeUGXd3Pnzh3RdFNtXbmeuuN66p7rqjuup+6NZF35wKWG2bNnM2vWrH5XY0KYij+mkXA9dcf11D3XVXdcT90bal0tWLCgeXAM/b3rYT6wfkTMAKj/r1eHj0WZJEnqUd+CQmbeAVwN7F4H7Q78MjPvHIuysV0aSZImp/G6PfIY4A3AusBFEXF3Zm4G7AecHBGHAfcCe3dMNhZlkiSpB+N118P7gfcPMfx64K8a04x6mSRJ6o1PZpQkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0GBUmS1GRQkCRJTQYFSZLUZFCQJElNBgVJktRkUJAkSU0z+10BgIi4GXi0/gP4UGZeEBHbAicCKwM3A3tm5h11mhGVSZKk7k2kFoU3ZeYW9d8FETEdOA14b2ZuClwKHAkw0jJJktSbiRQUBpsDPJqZl9X3JwBvXsYySZLUg4kUFL4VEddGxPER8XRgQ+CWgcLMvAuYHhHPXIYySZLUgwlxjQKwfWbOj4hZwBeAY4Hv9bNC8+bNG3L4nDlzxrkm/Td37twRTTfV1pXrqTuup+65rrrjeureSNbVhAgKmTm//r8gIo4HzgG+CGw0ME5ErAUsysx7IuLWkZT1UqfZs2cza9asZVmsSWMq/phGwvXUHddT91xX3XE9dW+odbVgwYLmwTFMgFMPEfG0iFijvp4GvAW4GpgLrBwR29VR9wPOrK9HWiZJknrQ96AArANcEhHXAvOATYH3ZOYiYC/gyxFxA7AD8GGAkZZJkqTe9P3UQ2b+FtiyUfZTYPPRLJMkSd2bCC0KkiRpgjIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkppn9rsBYiYhNgZOBNYG7gb0z84b+1kqSpOXLZG5ROAE4LjM3BY4DTuxzfSRJWu5MyqAQEc8CtgLOqIPOALaKiLX7VytJkpY/k/XUwwbAbZm5ECAzF0bE7XX4nUuZdgbAY4891hzhadNXGKVqTnwLFixYpumfWHGVUarJxLas62nFFaaNUk0mtmVdT4tWnBrrCZZ9Xa3AqqNUk4ltmbdRPH10KrIcaK2rjv3djKHKpy1evHiMqtQ/ETEHOCUzN+sY9mtgz8z8xXDTzp07dzvgJ2NcRUmSJprt58yZc9nggZO1RWE+sH5EzKitCTOA9erwpbkK2B74A7BwDOsoSdJEMAN4NmX/t4RJ2aIAEBGXAF/LzNMiYk9g38z86z5XS5Kk5cpkDgovpNwe+QzgXsrtkdnfWkmStHyZtEFBkiQtu0l5e6QkSRodBgVJktRkUJAkSU0GBUmS1GRQkCRJTQaFHkXEzRFxfURcExE3RsT3I+JlfazP4RGxYpfj/iAiNh7rOnUrIj4ZEV/ueP/aiFgcEZ1P1Dw3IvZtTP/ciLir4/3iiFjiubUR8YmI+IfRrv94GWq5IuKuiHjuCOf39Ig4pIfxr46IlUfyWRNBROwWEb+sy3F9RJxeh/95uSLiwNpHzMA0O0bE33W8Xy8iLh7/2o+Pul2bPQrzWa5/a52G+d50vc3t8fP+/DeYaNvqyfpkxrH2psycBxARbwB+EBGvyswr+1CXjwFHA+3OKarMfM1QwyNiZmY+MdoV68LFwLEd73cArgR2BK6rT9TcDvi/y/IhmXnYskw/CT0dOAQ4qpuRM3OLoYb38XvTtYh4NnA8sFVmzo+IacAWsMRyHQhcBNxR3+8IrApcWMe9HfCBbUsxWX5rw31v6GGbO1KtbXW/GBSWUWaeFRHbAB+MiLcDXwK2rsWnZOZRERHAWZm5WUTMBO4GPpmZn4mINwO7ZuYe9WmSVwEvpTxy+juZ+WGAiPgYsDvwKLCYstE6on7OTyNiEWXj9hrKjnUg8X4wM39Y53Ez8NrMnFc/62pgW+CeiHgbcDqwTp3uosz8wOitqSH9FHheRKyTmf9LCQofB95G6Rp8S+ABYP+I2KEu013AOzLzltZMI2I68Flg3TqvE4GfZ+axEXE4EMAawPOBm4DdMvPhiFgD+DqwGXBb/XdHZn5wlJd7VNW/67eBv6Us1xfqsk6nBLG/ARYAD2Xmyynr9ukRcTXwcGa+LCIOBt5C2SY8CuyfmVfX+S8GVsvMhzo+62+AX0XEUcA3gVUoj4H9ZmYePR7L3aV1gccpvzkyczHwS3hyuSi/l/WAf4+IR4F9gP2A6RGxE2V5v035Dq3VMe2/AK8H1gT+KTO/W8veSPltPgKcWV+vlpkPjccCj5aIOJrym3zK7y4ijgNuzszP1PG2pKyfFwLfYHL81ob83tRlh962uadQfpvPBo7OzGNr2faUMALwY+DPPZ4Nsa1u7RdeTFnnT6Nsz19A2becO2prAk89jJYrKV/4j1LW6ebAy4B9ImLn+kTI1WtK3Rq4DnhlnfaVwA875rUh8ArKTvIfI2KTiHgm8AFgy3oU9ArKRv+9dZqXZeYWmXkfcAGwbWZuSdnwnzxMvZ8PbFfT61uBmzJz88zcHPjEyFdHdzLzEeBnwI4RsRrly34+Tyb3HYFLgCMzc+vMfAmly/BPDzPblYDvAE8Ae2TmUN2l/SWwB/AiYAXKsgMcBtybmS8EdqP0+bG8eFZmzgFeDnwkIv4CeAklUL64rrvX1nHfC9xXvzMDp81Oqet4S8r3+IRhPmv1zNwmM/cF3gOck5kvyczZwEljsGzL4hrKd+zWiPj3eophzc4RMvMI4HZKS+EWmXkNZflPqe+PbMz7gczcGtgLOAYgItYBvgLsUtflI2OzWOOi9bs7Fnh3PcoGOAA4vu5MB1tef2tDfm9GuM1dJTNfStmeHRkRq0bELEq4el/d3l5K2fa3LLFfqMNPBb5Uf3tf4MmD1FFlUBgdAz+YnYCvZubizHyA8uPaqZb9iBIKdqIc4W5Qz3PtVMsGnJmZizLzfuB/gI2B+4EbgVMi4p3AqsM0+W4MXBAR1wH/BqwbEes2xj29Yz5XADtHxGci4rXAeB39XEL5AW0HXFa7Br+hXqewI+X0xM4RcUVEzAM+yJNBYijnA1dk5j81NlwAF2TmfbX8Sso6g7JT/QZAZt4DnD3yxRoXnct3EkBtmflPyrr7LWXjfFJE7LWUec2JiEvrOv4cw6/jUzpeX0rZcP2/iPgb4L5eFmCs1d/Srjz5Xfo/wLU1fC+rb9f/rwDWi4iVgL8CfpGZN9Syr4/C5/TLkL+7zPwfynfr1RHxDODvKa1KQ1kuf2s9fm+Wts39dp3nzZTuBJ5DaWl5ODMvqWXfoWznW5bYL0TE6sBsSkswmflz4NqRLO/SGBRGx9bAvKWMMxAUBloQrqCcSpiWmb/rGO/RjtcLgZl157ktJck/B5hbjxiHcgYl3W8GbEU5sl6pMe6fw0BmXk5Jq3MpR0jjdeHWxZQf4w6U5jcoO59XUsLDb4HPA7vX1PwO2ssDJXi8OiJWGWacJdbxSCo+ju6kNG8D5doASnPuncNNVDcqm1E2VH9Bue5jidBYA+u/AwfWdfxqYNYws+783nyXcjR4E/BhyhHOhJOZ8zLzuMz8W8oGecdRmO2jdd4DvcxO9O9R1yJiI4b/3R1DaU16B+W0amsnt7z91p6iy+/N0ra53a6D4fpTGG4eY94Pg0FhGUXE64D9KefELwL2jYhptSn9LcB/1VF/CLwKeEZm/r6O+3Geetqh9RmrAWtn5o8z82OUUDJwhfKDlJ3GgKcDA8HjHQy/we/8jOdRmlK/DRxEOcIcj+/H5cBzgTdSdvJQgsIBlKPTeygXDf2x1me/pczvcMo6v6Am7l5cAuwN5c4A4HU9Tj9W/gt4d8f7d1FaTR7uGPY2gIhYm3LO9OL6epXMvICyE7+fcrrpAWCVGjigbNRm8mQ37O/ptmIR8QLgj5n5Tcr3eZuelmyMRcT6EfHSjvfPAdbmyd/IgAd46u9o8PtuXQls1XHF+j4jmMdEsDrD/+5+QDkqPohyzUuvLmFi/taApX5vRmObm8DK9ToFIuJNdT5dq63W11EOOImIrSinvUfdcpXuJpB/j4gFlHPqvwZek5lX1qanY4Ff1fFOzczzATLz9xHxIHBZLfsR5bzTj1i6NYDvRrmVazrwC+CsWvZZ4EcR8Qgl7R4InB0R91Ka4e/ucpl2BA6KiIX1M/bLzEVdTjtimfloRFwJrJ/lynIoF+6sT2lu+1VEnElZz3dRNlCvWMo8P13Xx0UR8eoeqvMJ4BsRcT3wB+DnDN8cOF4OBL4YEdcCiyg79MGnEu6KiLmU78q/1vW2FfDVGghmAudRAsaiiPgW5WLEe7NczHgYcFVE3E1pXejWm4G3RsRjlCObZbpDZQzMBD5ej5AfoXy3D83MX0ZE53jHUP72D1POqX8P2Lte8DlwMeNSZeb/RsR+lDuhHgbOpVwU9/DwU04IF0VE5ynN5u+ufodOBnbOzJE0d0/U39qA4b43y7zNzcwFEbE7cHy9MPZS4NYR1HNv4OsR8c+U/c6vGIP1aO+RUhURKwAzanhZnRLqDsrMi/pctWF1XiHd77qotABm5oP19duBfTNzuz5Xa9RFxH8BX8nMM0cw7XL5W5toojxf5U+ZubjeAXEJEJl572h+ji0K0pOeAZwX5fkNK1Eu9nTDpV69PyJ2o2xf7wHe2ef6jKqI+EvKRXu/BL47wtn4WxsdLwM+03EHyjtHOySALQqSJGkYXswoSZKaDAqSJKnJoCBJkpoMCpKaovSUd1q/67E0UXre22npY47utNJU4F0P0hQXEXtQHpzzQsrDZK4GjsjMy4abbozqshjYJDNvHO/PljQ0WxSkKSwiDqJ0JvMpSs+hG1J6tJtQT8qT1D+2KEhTVJSufj8BvD0zz+oo+o/6b6hpzqT07bAypYe9/TPzulr2GuBoYAPKI5A/n5lHR8RalE6DtqM8WfI6YIdenvxZH4n8VUqPmIspPfa9t/beN2DriDiG0p3v2bVuj9bpXwt8kvK48F9Tnjy6xBMFo3QZfzywKeWJfN/KzIO6rac0GdmiIE1dL6U87OZ7PUxzHrAJ8CzKo8S/1VF2EvDuzFyN0hfJwOPJDwZ+T3lW/jrAR+i9I5tpwL8C61G6LN6A0q9Hp7dS+lPZmLKjPxQgIrak9OL4bkrnWicC59Sufgf7IvDFzFy9zuc7PdZTmnRsUZCmrjWBu4bpsnwJmfnnbpMj4nDg3ohYo/Ye+Djw4oi4pj4dbuAJcY9TjvI3qtce/KTXitbpBq5buDMiPgd8bNBox2bm/Fq3I4AvUcLCu4ATM/PKOt7JEfERSo+sPx40j8eBF0TEWpl5F6WXV2lKMyhIU9fdwFoRMbObsFAft3sEsBuldWDg1MFalI5o3kjZMR9ZO7D6cO2+/DOUo/8La0dMX8nMI3upaESsQzna3x5YjdIaOvhRtfM7Xt9CaX0A2AjYJyLe11G+Ykd5p30pp2Ouj4jfAR/PzHN7qas02RgUpKnrcmABsCvd9Ri5B+Uix52Amyk9Vd5LOS1AZl4FvK52+HMApdl+g9pB0sHAwRExm9Lz3lWZudQu1jt8inK6YvPMvCcidqX01Nppg47XGwIDvZHOp9zFccTSPiQzbwB2r10rv4HSU+yamfmnHuoqTSoGBWmKysz7a/fSx9XuhS+kNL3vBPx1Zh4yaJLVKMHibmAVys4bgIhYkdLScG6d7wPUFod6IeH1wE2UloeFPNkaMZQVI2KljveP18++H7g/ItYH/mmI6d4bEedSunT+F0rHRVAugvxeRFwE/KzWfUfg0oFeHjuWY0/ggsy8MyLuq4PHvLt1aSLzYkZpCsvMz1KeoXAocCfl6PsAyl0Dg51CadK/jXLnwODz93sBN9eQsB/l4kIoFz9eBDxEacU4PjMvHqZa11HuOBj493bg48BWlLDwn8BZQ0x3OiXs/JYSSj5Zl/HnlB4cj6W0gNwIvK3x2a8GrouIhyinOt6SmY8MU1dp0rP3SEmS1GSLgiRJajIoSJKkJoOCJElqMihIkqQmg4IkSWoyKEiSpCaDgiRJajIoSJKkJoOCJElq+v+MDXk+j6UZugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Checking class balance\n",
    "class_counts = df_filtred['Label'].value_counts()\n",
    "print(\"Class Counts:\\n\", class_counts)\n",
    "\n",
    "# Plotting class balance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.countplot(x='Label', data=df_filtred, palette=\"Set2\")\n",
    "plt.title('Class Distribution Before Balancing')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# # Displaying percentages on top of the bars\n",
    "# total = len(df_filtred['Label'])\n",
    "# for i, count in enumerate(class_counts):\n",
    "#     plt.text(i, count + 0.1, f'{count/total*100:.2f}%', ha='center')\n",
    "\n",
    "# Save the plot to a file if needed\n",
    "# plt.savefig('class_balance_plot.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3984555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176070, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1_Ax</th>\n",
       "      <th>S1_Ay</th>\n",
       "      <th>S1_Az</th>\n",
       "      <th>S1_Gx</th>\n",
       "      <th>S1_Gy</th>\n",
       "      <th>S1_Gz</th>\n",
       "      <th>S2_Ax</th>\n",
       "      <th>S2_Ay</th>\n",
       "      <th>S2_Az</th>\n",
       "      <th>S2_Gx</th>\n",
       "      <th>S2_Gy</th>\n",
       "      <th>S2_Gz</th>\n",
       "      <th>S3_Ax</th>\n",
       "      <th>S3_Ay</th>\n",
       "      <th>S3_Az</th>\n",
       "      <th>S3_Gx</th>\n",
       "      <th>S3_Gy</th>\n",
       "      <th>S3_Gz</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-84.222490</td>\n",
       "      <td>-994.627346</td>\n",
       "      <td>8.055153</td>\n",
       "      <td>-0.370396</td>\n",
       "      <td>-2.620791</td>\n",
       "      <td>1.649596</td>\n",
       "      <td>311.291489</td>\n",
       "      <td>-1061.332673</td>\n",
       "      <td>81.294603</td>\n",
       "      <td>2.077435</td>\n",
       "      <td>-3.234044</td>\n",
       "      <td>-4.329407</td>\n",
       "      <td>-68.121248</td>\n",
       "      <td>-970.461276</td>\n",
       "      <td>150.138268</td>\n",
       "      <td>1.829730</td>\n",
       "      <td>0.240081</td>\n",
       "      <td>0.610366</td>\n",
       "      <td>Downstairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.069874</td>\n",
       "      <td>-998.773910</td>\n",
       "      <td>11.651440</td>\n",
       "      <td>-0.282880</td>\n",
       "      <td>-3.161370</td>\n",
       "      <td>0.810362</td>\n",
       "      <td>301.127326</td>\n",
       "      <td>-1027.592784</td>\n",
       "      <td>86.576920</td>\n",
       "      <td>6.452058</td>\n",
       "      <td>2.962058</td>\n",
       "      <td>-3.769370</td>\n",
       "      <td>-70.387323</td>\n",
       "      <td>-977.643665</td>\n",
       "      <td>146.687971</td>\n",
       "      <td>0.477777</td>\n",
       "      <td>-0.317638</td>\n",
       "      <td>0.282808</td>\n",
       "      <td>Downstairs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       S1_Ax       S1_Ay      S1_Az     S1_Gx     S1_Gy     S1_Gz       S2_Ax  \\\n",
       "0 -84.222490 -994.627346   8.055153 -0.370396 -2.620791  1.649596  311.291489   \n",
       "1 -88.069874 -998.773910  11.651440 -0.282880 -3.161370  0.810362  301.127326   \n",
       "\n",
       "         S2_Ay      S2_Az     S2_Gx     S2_Gy     S2_Gz      S3_Ax  \\\n",
       "0 -1061.332673  81.294603  2.077435 -3.234044 -4.329407 -68.121248   \n",
       "1 -1027.592784  86.576920  6.452058  2.962058 -3.769370 -70.387323   \n",
       "\n",
       "        S3_Ay       S3_Az     S3_Gx     S3_Gy     S3_Gz       Label  \n",
       "0 -970.461276  150.138268  1.829730  0.240081  0.610366  Downstairs  \n",
       "1 -977.643665  146.687971  0.477777 -0.317638  0.282808  Downstairs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# split data into input and output elements\n",
    "X = df_filtred[['S1_Ax', 'S1_Ay', 'S1_Az', 'S1_Gx', 'S1_Gy',\n",
    "       'S1_Gz', 'S2_Ax', 'S2_Ay', 'S2_Az', 'S2_Gx', 'S2_Gy', 'S2_Gz', 'S3_Ax',\n",
    "       'S3_Ay', 'S3_Az', 'S3_Gx', 'S3_Gy', 'S3_Gz']]\n",
    "y = df_filtred[['Label']]\n",
    "\n",
    "oversample = SMOTE()\n",
    "Xo, yo = oversample.fit_resample(X, y)\n",
    "\n",
    "df_Smoted=pd.concat([Xo,yo],axis=1)\n",
    "print(df_Smoted.shape)\n",
    "df_Smoted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3ebad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      " Downstairs    29345\n",
      "Walking       29345\n",
      "Upstairs      29345\n",
      "Sitting       29345\n",
      "Laying        29345\n",
      "Standing      29345\n",
      "Name: Label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAGJCAYAAADrDRu+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6gElEQVR4nO3deXgO5+L/8U92SxB7E1XKEbROiURSBBVUxBJ6qjSWlnLsdLFTS1Dr0e+hRbVO+muP0tNvSyRqb2sppVFbqi1tVbUJQYSEyPbM7w9fc4QMTyIb3q/rcl155p7lntvM83zmns3BMAxDAAAAOXAs6goAAIDii6AAAAAsERQAAIAlggIAALBEUAAAAJYICgAAwBJBAfe8xYsXa/To0UVdjWwGDBigNWvW5Mu8YmJi1L59e/NzUFCQdu/enS/zlqSOHTtq7969+TY/e/36668KDQ2Vj4+PPvjgg0Jf/v1q7969atmyZYEu4+ZtEvc356KuAGCPqKgoRURE6MSJEypdurTq1aunwYMHy8/Pr9DrUrduXZUsWVIODg5ydXVVvXr11KNHD4WEhJjjvPfee3bPa/PmzapRo4blOH5+ftq0adNd11uSxo8fr6pVq+qVV14xh61fvz5f5n27Za5bt05fffWVqlSpYg5/7733FBAQoMjISEnXAtDMmTPVrFmzfFt2TEyMFixYoOPHj8vJyUm1atXSxIkT9cQTT+izzz7ThAkT9MILL2jixInmNFu3btWwYcPUrVs3zZkzR5KUnp6uxYsXKyoqSomJiXrooYf03HPP6aWXXpKDg4M6duyouLg4SdLVq1fl7OwsZ+drX6+DBg1SlSpVNGnSJJUoUSJb/TZu3KiqVaveUu+bt7HmzZtr2rRpKlu2bL61zd3Iz20SxR9BAcVeRESEli9frunTpyswMFAuLi7auXOntm3bViRBQZIiIyNVo0YNJSYmaseOHQoPD9evv/6q4cOH5+tyMjMzzR+ce9GVK1e0adMmlSlTRuvWrdOAAQPMsri4OHXs2DFflmMYhgzDkKPjfztJU1JSNHjwYE2bNk0dOnRQRkaGYmJi5Orqao7zyCOPaMOGDRo7dqzZzmvXrlXNmjWzzX/kyJE6d+6cli9frlq1aik2NlZjx47V6dOnNXny5Gxhq0+fPurSpYu6d+9uDvvss8/UqFEjrVq1yu51ur6NpaSkaNSoUVq8eLEmTZqU26YB7hqnHlCsJScna9GiRZoyZYqefvpplSpVSi4uLgoKCtK4ceNynGbkyJFq3ry5fH191atXLx0/ftws2759u0JCQuTj46MWLVpoxYoVkqTExEQNGjRIfn5+8vf3V1hYmGw22x3rV6FCBXXt2lXTpk3TO++8owsXLki69mPxySefSJJOnjyp3r17y9fXVwEBAXr55ZclSb169ZIks/v9888/N7uNly9frubNm2vChAk5diUfOXJEISEhatKkiSZMmKC0tDRJ136Qnn/++Wzj1q1bVydPntTHH3+sqKgorVixQj4+Pho8eLCk7Kcy0tPTNWvWLAUGBiowMFCzZs1Senq6pP92af/rX/9S06ZNFRgYqE8//fS27bN582aVLVtWQ4cO1dq1a83hffv21d69exUeHi4fHx+9+uqriouL0+DBg+Xj46N3331XknTw4EH17NlTfn5+6tKlS7ZTJH369NGbb76pnj17qmHDhjp16lS2ZZ84cUKS1KlTJzk5OalEiRIKDAxUvXr1zHEqVaokb29v7dq1S5KUlJSkAwcOKCgoyBxnz549+vrrr7V48WJ5e3vL2dlZjRo10vz587Vy5UqdPHnytm1wt9zd3RUUFKRffvnFHPbpp5+qQ4cO8vHxUZs2bbR69WrL6ZcvX662bdvKx8dHISEh2rJli1l2fXuZO3eumjRpoqCgIG3fvt0sT0pK0oQJExQYGKgmTZpo6NChkm49vREUFKQVK1aoc+fO8vX11csvv2xuk5L07rvvmtvUJ598Ym6TuDcQFFCsHThwQGlpaWrXrp3d07Rs2VKbNm3Snj179Nhjj2W7fmHSpEkKDw/XgQMHFB0drSeffFLStV6LqlWrmj8Kr776qhwcHOxeZps2bZSVlaXDhw/fUvbPf/5TzZs317fffqsdO3aod+/ekqSVK1dKunbkeODAAfPUxblz53Tx4kV9+eWXmjFjRo7Lu/6Dv2XLFp04cUJLliy5Yx179Oihzp0766WXXtKBAwe0bNmyW8ZZunSpDh06pMjISK1bt05HjhzJNu9z584pOTlZO3bs0KxZsxQeHq6LFy9aLnPNmjXq2LGjOnbsqF9//VWxsbGSpA8++EB+fn6aMmWKDhw4oIULF8rLy0vLli3TgQMHNHDgQJ05c0aDBg3SkCFDtG/fPo0bN04jR45UYmKiOf/IyEjNmDFD3333nby8vLIt+9FHH5WTk5PGjRun7du3W9aza9euZohZv3692rRpk63X4euvv1bDhg3l6emZbbqGDRvqoYce0p49eyzXPz9cvHhR27ZtU8OGDc1hFStW1DvvvKPvvvtOs2fP1uzZs/X999/nOH316tW1cuVK7d+/X8OHD9eYMWOUkJBglh8+fFiPPvqovvnmGw0YMECTJk3S9Sf7jx07VqmpqVq/fr12796tF1980bKeGzZs0Hvvvadt27bpp59+0meffSZJ2rFjh95//31FRERoy5YtRXI9DO4OQQHFWlJSksqXL5+r7vdnn31W7u7ucnV11YgRI/Tjjz8qOTlZkuTs7Kyff/5ZKSkpKleunB5//HFz+NmzZxUXFycXFxf5+fnlKii4uLiofPnyOf4YOTs7Ky4uTgkJCXJzc7vj6RJHR0eNHDlSrq6ut5zTvq5Xr17y9PSUh4eHhgwZkm/XGURFRWnYsGGqWLGiKlSooGHDhmndunXZ1mXYsGFycXFRq1atVKpUKfPI/WZxcXHau3evOnfurEqVKqlp06bZehXuJDIyUi1btlSrVq3k6Oio5s2bq0GDBtmOeLt166Y6derI2dlZLi4u2aZ3d3fXRx99JAcHB73++utq2rSpBg8erHPnzmUbr127dtq3b5+Sk5MVGRmp0NDQbOUXLlxQ5cqVc6xj5cqVzV6kOzl06JD8/PzMf23btr3t+N26dZOfn5+efPJJxcXFqWfPnmbZU089pUceeUQODg7y9/dX8+bNFRMTk+N8OnTooKpVq8rR0VEhISGqUaNGtkDr5eWl5557Tk5OTurWrZvOnj2rc+fOKSEhQTt27ND06dNVrlw5ubi4yN/f37K+ffr0UdWqVeXh4aHWrVvrhx9+kHQtQDzzzDOqU6eOSpYsqREjRtjVXig+CAoo1jw8PHThwgVlZmbaNX5WVpYWLFigtm3bqnHjxmYX8vUv80WLFmn79u1q3bq1evfurQMHDkiSXnrpJdWoUUP9+/dXmzZttHz58lzVMyMjQ4mJiSpXrtwtZWPGjJFhGHr22WfVsWNH/e///u9t51W+fHm5ubnddpwbj269vLyyHSHejYSEhGxH5jfP28PDI1toK1mypK5cuZLjvCIjI1W7dm3Vr19fktS5c2dFR0crIyPDrrrExcVp48aN2X5c9+/fr7Nnz5rj3HyUf7PatWtrzpw52rFjh6KiopSQkKA33ngj2zglSpRQq1attGTJEiUlJcnX1zdbefny5bMt80Znz55V+fLl7Vqfhg0bKiYmxvy3devW246/Zs0axcTE6PDhw3r++ecVFhZmdudv375dzz33nPz9/eXn56cdO3ZYBpa1a9cqNDTUbMPjx49nG7dSpUrm3yVLlpR07dqS06dPq1y5cjlu0zm5MUzduF0kJCTooYceMsvu9H+G4oeggGLNx8dHrq6ud/xSvS4qKkrbtm1TRESE9u/fry+++EKSzK7UJ554QkuXLtXu3bvVtm1b83oBd3d3jR8/Xtu2bdPSpUsVERGRqy7lbdu2ycnJSU888cQtZZUrV9bMmTO1a9cuTZ8+XdOnT7/t+Vl7ejLi4+PNv+Pi4sy7CUqWLKmrV6+aZTf/wN1p3lWqVDGv3r++nBvvVMiNtWvX6tSpU2revLmaN2+u2bNn68KFC9l6BG7H09NToaGh2X5cDx48qL///e92r8+NateurWeeeSbbNSvXde3aVREREerSpcstZc2aNdOhQ4eytbkkc9j101cFxcXFRd27d9cff/yhY8eOKT09XSNHjlT//v319ddfKyYmRi1btlROLwL+888/NXnyZL3++uvau3evYmJiVKdOHbuW+9BDD+nixYu6dOnSXdW/SpUqOnPmjPn55nZE8UdQQLFWpkwZjRw5UuHh4dq6datSU1OVkZGh7du3a968ebeMf/nyZbm6uqp8+fJKTU3VwoULzbL09HStW7dOycnJcnFxUenSpc2r5L/88kudPHlShmGoTJkycnJysutHKCkpSevWrVN4eLgGDhyY49Hlhg0bdPr0aUlSuXLl5ODgYC63UqVKt1yEZ4+PPvpIp0+fVlJSkpYtW2Ze31CvXj0dP35cP/zwg9LS0rR48eJs01WsWFF//PGH5Xw7duyopUuXKjExUYmJiXr77bfVuXPnXNfvwIEDOnXqlD755BOtXbtWa9euVXR0tDp16mTeDnmzm9uiS5cu+vLLL7Vz505lZWUpLS1Ne/fuNdvyTn755Rf961//MsePj49XdHR0tnP91/n7+ysiIsK8fuRGzZo1U9OmTTVixAgdP35cWVlZOnjwoMaMGaPnn3/+ljsk8ltWVpY+++wzlShRQtWrV1d6errS09NVoUIFOTs7a/v27fr6669znDY1NVUODg6qUKGCpGsXQeYUlHJSpUoVtWzZUtOnT9fFixeVkZGhb7/9Ntf1Dw4O1meffaZffvlFqampdl1Pg+Ll3r3vCg+M/v37q1KlSlqyZIlGjx6t0qVL6/HHHzev2r9R165dtWvXLrVo0UIeHh4aNWpUtlvSrl/8lpWVpUcffVTz58+XdO3OhBkzZigxMVFly5bV888/f9sjxdDQUDk4OMjFxUV169bVhAkTLH9Qjxw5ojfeeEMpKSmqWLGiJk2apOrVq0uShg8frvHjx+vq1asKDw9XxYoV7WqTTp06qX///kpISFCbNm00ZMgQSdcu4Bs2bJhefPFFlShRQq+++qo+/vhjc7pnn31Wo0aNMu/uuPlLe+jQobp8+bJ5ZB0cHGxe6Z4ba9asUZs2bVS3bt1sw1944QWFhYUpKSnplmn+/ve/a+bMmZo/f76GDBmil156SUuWLNH8+fP12muvydHRUU888YSmTZtmVx3c3d116NAhRUREKDk5WWXKlFHr1q01duzYW8Z1cHBQ06ZNLee1ePFiLVq0SAMGDNCFCxdUtWpVde/ePdvtnndy8OBB+fj4ZBv2//7f/8uxF0r67zbm4OCgRx99VG+99ZY8PDwkSZMnT9bLL7+s9PR0tW7dOttdGjf6y1/+ov79+6tnz55ycHBQ165d1bhxY7vrPG/ePM2ePdu8vTQgIEBNmjSxe3pJatWqlfr06aO+ffvKwcHBvAPmxgtGUbw5GDn1VwEAUAB++eUXderUSUeOHLmnnxHyIOHUAwCgQG3ZskXp6em6ePGi5s+fr9atWxMS7iEEBQBAgVq9erWaNm2qdu3aycnJye7TRygeOPUAAAAs0aMAAAAscZLoJjabTZcvX5aLi0uu7tEGAOBeZBiGMjIyst0yfiOCwk0uX76sY8eOFXU1AAAoVN7e3ipTpswtwwkKN7n+vHhvb2/u8wUA3PfS09N17NixW96Xch1B4SbXTze4urre8Xn7AADcL6xOt3MxIwAAsERQAAAAlgotKAwdOlRdunRR165dFRYWZr6r/MSJE+rRo4fat2+vHj166LfffjOnKYgyAACQC0YhuXTpkvn3li1bjK5duxqGYRh9+vQx1q5daxiGYaxdu9bo06ePOV5BlN3J1atXjZiYGOPq1au5XUUAAO45d/rdK7QehRtvuUhJSZGDg4POnz+vo0ePqlOnTpKuvRHv6NGjSkxMLJAyAACQO4V618OkSZP09ddfyzAMvffee4qPj1fVqlXl5OQkSXJyclKVKlUUHx8vwzDyvez6O9kBAIB9CjUozJo1S5K0du1azZs3T6NGjSrMxedKbGxsUVcBAIAiVyTPUejataumTJmihx56SGfOnFFWVpacnJyUlZWlhIQEeXp6yjCMfC/LjQYNGvAcBQDAfS8tLe22B8eFco3C5cuXFR8fb37+4osvVK5cOVWsWFH169dXdHS0JCk6Olr169dXhQoVCqQMAADkTqG8ZvrcuXMaOnSoUlNT5ejoqHLlymncuHF6/PHH9csvv2j8+PG6dOmSypYtq7lz56pWrVqSVCBld3I9WdGjAAB4ENzpd69QgsK9hKAAAHiQ3Ol3jyczAgAASwQFAABgiaCQSxlZWUVdhUJ1N+trZGbkY02Kt7tZ18wsWz7WpHi7m3W1ZT447STd3fpm2R6cfe9u1tWwpedjTYq/vK4vr5nOJRcnJ7224YOirkah+UeHvnme1sHZRQlLx+ZjbYqvKkPm5XlaZydHLfn3rnysTfE1tHdgnqd1dHbUz0u352Ntire/DGmV52mdHF304d6/52Ntiq8+AcvzPK2Do6vi9oXkY22KNy//z/M0HT0KAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlpwLYyEXLlzQ2LFj9fvvv8vV1VU1atRQeHi4KlSooLp168rb21uOjtcyy7x581S3bl1J0hdffKF58+YpKytLjz/+uGbPnq2SJUveVRkAALBfofQoODg4aMCAAdq0aZOioqJUvXp1LViwwCxfvXq1IiMjFRkZaYaEy5cv6/XXX9eyZcu0ZcsWlS5dWitWrLirMgAAkDuFEhQ8PDwUEBBgfm7UqJHi4uJuO82OHTvUoEED1axZU5LUs2dPbdiw4a7KAABA7hTKqYcb2Ww2rVq1SkFBQeawPn36KCsrSy1bttSIESPk6uqq+Ph4eXl5meN4eXkpPj5ekvJcBgAAcqfQg8KMGTNUqlQp9e7dW5L01VdfydPTUykpKRozZozefvttvfLKK4VdrVvExsbmONzX17eQa1L09u/fn6fpHrS2op3sQzvZj7ayD+1kv7y0VaEGhblz5+rkyZNatmyZefGip6enJMnd3V3du3dXRESEOXzv3r3mtHFxcea4eS3LjQYNGsjNzS3X092PHsSdKS9oJ/vQTvajrexDO9kvp7ZKS0uzPDiWCvH2yIULFyo2NlZvv/22XF1dJUkXL17U1atXJUmZmZnatGmT6tevL0lq0aKFjhw5ot9++03StQseO3TocFdlAAAgdwqlR+H48eN65513VLNmTfXs2VOS9PDDD2vAgAGaMmWKHBwclJmZKR8fH40aNUrStR6G8PBwDRo0SDabTfXr19ekSZPuqgwAAOROoQSFOnXq6KeffsqxLCoqynK6tm3bqm3btvlaBgAA7MeTGQEAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAUqEEhQsXLmjgwIFq3769OnfurOHDhysxMVGSdPDgQXXp0kXt27dX//79df78eXO6gigDAAD2K5Sg4ODgoAEDBmjTpk2KiopS9erVtWDBAtlsNo0ZM0ZTpkzRpk2b5OfnpwULFkhSgZQBAIDcKZSg4OHhoYCAAPNzo0aNFBcXp9jYWLm5ucnPz0+S1LNnT23cuFGSCqQMAADkTqFfo2Cz2bRq1SoFBQUpPj5eXl5eZlmFChVks9mUlJRUIGUAACB3nAt7gTNmzFCpUqXUu3dvbdmypbAXb7fY2Ngch/v6+hZyTYre/v378zTdg9ZWtJN9aCf70Vb2oZ3sl5e2KtSgMHfuXJ08eVLLli2To6OjPD09FRcXZ5YnJibK0dFRHh4eBVKWGw0aNJCbm1veV/Y+8iDuTHlBO9mHdrIfbWUf2sl+ObVVWlqa5cGxVIinHhYuXKjY2Fi9/fbbcnV1lXTtx/jq1auKiYmRJK1evVrBwcEFVgYAAHKnUHoUjh8/rnfeeUc1a9ZUz549JUkPP/yw3n77bc2bN09Tp05VWlqaqlWrpvnz50uSHB0d870MAADkTqEEhTp16uinn37Ksaxx48aKiooqtDIAAGA/nswIAAAsERQAAIAlggIAALBEUAAAAJYICgAAwBJBAQAAWCIoAAAASwQFAABgiaAAAAAsERQAAIAlggIAALBEUAAAAJYICgAAwBJBAQAAWCIoAAAASwQFAABgiaAAAAAsERQAAIAlggIAALBEUAAAAJYICgAAwBJBAQAAWCIoAAAASwQFAABgiaAAAAAsERQAAIAlggIAALBkd1DYsGFDjsM3btyYb5UBAADFi91BYdKkSTkOnzJlSr5VBgAAFC/Odxrh1KlTkiTDMMy/byxzdXUtmJoBAIAid8eg0K5dOzk4OMgwDLVr1y5bWaVKlTRixIgCqxwAAChadwwKP/74oySpd+/e+ve//13gFQIAAMWH3dcoEBIAAHjw3LFH4bpTp07pf/7nf/TDDz/oypUr2cq++uqr/K4XAAAoBuwOCqNHj1b16tU1btw4lSxZsiDrBAAAigm7g8Lx48e1atUqOTryjCYAAB4Udv/qN2nSREePHi3IugAAgGLG7h6FatWqacCAAWrXrp0qVaqUrWzUqFH5XjEAAFD07A4Kqampat26tTIzM3X69OmCrBMAACgm7A4Ks2fPLsh6AACAYihXt0daqV69er5UBgAAFC92B4UbH+V8nYODgyTphx9+yP+aAQCAImd3ULj+KOfrzp49q7feekt+fn75XikAAFA85PmhCJUrV9akSZO0cOHC/KwPAAAoRu7q6Um//vqrUlNT7Rp37ty5CgoKUt26dXXs2DFzeFBQkIKDgxUaGqrQ0FDt3LnTLDt48KC6dOmi9u3bq3///jp//vxdlwEAAPvZfeohLCzMvCZBuna75M8//6xhw4bZNX2bNm3Ut29f9erV65ayRYsWydvbO9swm82mMWPGaPbs2fLz89OSJUu0YMECzZ49O89lAAAgd+wOCt27d8/2uWTJkqpXr55q1qxp1/S5vZYhNjZWbm5u5nQ9e/ZUmzZtNHv27DyXAQCA3LE7KHTr1q3AKjF69GgZhiFfX1+9+uqrKlu2rOLj4+Xl5WWOU6FCBdlsNiUlJeW5zMPDo8DWAQCA+5HdQSEjI0NLly5VZGSkEhISVKVKFYWGhmrw4MFydXXNcwVWrlwpT09Ppaena9asWQoPD9eCBQvyPL/8Ehsbm+NwX1/fQq5J0du/f3+epnvQ2op2sg/tZD/ayj60k/3y0lZ2B4X58+fr8OHDmj59ury8vBQXF6clS5YoJSVFEydOzPWCr/P09JQkubq6KiwsTEOGDDGHx8XFmeMlJibK0dFRHh4eeS7LjQYNGsjNzS3P63U/eRB3prygnexDO9mPtrIP7WS/nNoqLS3N8uBYysVdDxs3btTSpUsVGBioWrVqKTAwUG+99ZY2bNiQt9pKunLlipKTkyVJhmHo888/V/369SVd+6G+evWqYmJiJEmrV69WcHDwXZUBAIDcsbtH4cYnMtoz/GYzZ87U5s2bde7cOfXr108eHh5atmyZRowYoaysLNlsNtWuXVtTp06VJDk6OmrevHmaOnWq0tLSVK1aNc2fP/+uygAAQO7YHRSCg4M1ZMgQDRs2TF5eXvrzzz+1dOlSu4/WJ0+erMmTJ98yfO3atZbTNG7cWFFRUflaBgAA7Gd3UBgzZoyWLl2q8PBwJSQkqGrVqurYsaN5TQEAALj/3PEahf3792v+/PlydXXVqFGjtGXLFh06dEibN29Wenq6jh49Whj1BAAAReCOQeGdd95RkyZNciwLCAjQsmXL8r1SAACgeLhjUPjhhx/UokWLHMuaNWt221sqAADAve2OQSElJUUZGRk5lmVmZury5cv5XikAAFA83DEo1KpVS7t27cqxbNeuXapVq1a+VwoAABQPdwwKL774oqZOnarNmzfLZrNJuvZmx82bN2vatGnq169fgVcSAAAUjTveHtm5c2edO3dO48aNU0ZGhjw8PJSUlCQXFxeNHDlSnTp1Kox6AgCAImDXcxT69eun7t2768CBA+ZbGH18fOTu7l7Q9QMAAEXI7gcuubu7W979AAAA7k92vxQKAAA8eAgKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAEkEBAABYIigAAABLBAUAAGCJoAAAACwRFAAAgCWCAgAAsERQAAAAlggKAADAUqEEhblz5yooKEh169bVsWPHzOEnTpxQjx491L59e/Xo0UO//fZbgZYBAIDcKZSg0KZNG61cuVLVqlXLNnzq1KkKCwvTpk2bFBYWpilTphRoGQAAyJ1CCQp+fn7y9PTMNuz8+fM6evSoOnXqJEnq1KmTjh49qsTExAIpAwAAuedcVAuOj49X1apV5eTkJElycnJSlSpVFB8fL8Mw8r2sQoUKuapfbGxsjsN9fX3zusr3rP379+dpugetrWgn+9BO9qOt7EM72S8vbVVkQaG4a9Cggdzc3Iq6GsXCg7gz5QXtZB/ayX60lX1oJ/vl1FZpaWmWB8dSEQYFT09PnTlzRllZWXJyclJWVpYSEhLk6ekpwzDyvQwAAORekd0eWbFiRdWvX1/R0dGSpOjoaNWvX18VKlQokDIAAJB7hdKjMHPmTG3evFnnzp1Tv3795OHhofXr12vatGkaP368lixZorJly2ru3LnmNAVRBgAAcqdQgsLkyZM1efLkW4bXrl1bn3zySY7TFEQZAADIHZ7MCAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACw5FzUFZCkoKAgubq6ys3NTZI0evRotWjRQgcPHtSUKVOUlpamatWqaf78+apYsaIk5bkMAADYr9j0KCxatEiRkZGKjIxUixYtZLPZNGbMGE2ZMkWbNm2Sn5+fFixYIEl5LgMAALlTbILCzWJjY+Xm5iY/Pz9JUs+ePbVx48a7KgMAALlTLE49SNdONxiGIV9fX7366quKj4+Xl5eXWV6hQgXZbDYlJSXluczDw6MwVwkAgHtesQgKK1eulKenp9LT0zVr1iyFh4erXbt2RVqn2NjYHIf7+voWck2K3v79+/M03YPWVrSTfWgn+9FW9qGd7JeXtioWQcHT01OS5OrqqrCwMA0ZMkR9+/ZVXFycOU5iYqIcHR3l4eEhT0/PPJXlRoMGDcyLKx90D+LOlBe0k31oJ/vRVvahneyXU1ulpaVZHhxLxeAahStXrig5OVmSZBiGPv/8c9WvX18NGjTQ1atXFRMTI0lavXq1goODJSnPZQAAIHeKvEfh/PnzGjFihLKysmSz2VS7dm1NnTpVjo6OmjdvnqZOnZrtNkdJeS4DAAC5U+RBoXr16lq7dm2OZY0bN1ZUVFS+lgEAAPsV+akHAABQfBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYImgAAAALBEUAACAJYICAACwRFAAAACW7tugcOLECfXo0UPt27dXjx499NtvvxV1lQAAuOfct0Fh6tSpCgsL06ZNmxQWFqYpU6YUdZUAALjn3JdB4fz58zp69Kg6deokSerUqZOOHj2qxMTEIq4ZAAD3FueirkBBiI+PV9WqVeXk5CRJcnJyUpUqVRQfH68KFSrcdlrDMCRJ6enpluOUdnTJv8oWc2lpaXc1faZrqXyqSfF2t+3k6uKQTzUp3u62nWyuD0Y7SXffVi5yz6eaFG93/R0lj/ypyD3Aqq2u/95d//272X0ZFO5GRkaGJOnYsWOW44RW8i6s6hS52NjYu5tBo875U5FiLv4u28nnLyXyqSbF291vT6XzpyL3gLttqzrOvfKpJsXbXW9TTq/lT0XuAWfv0FYZGRkqUeLW76L7Mih4enrqzJkzysrKkpOTk7KyspSQkCBPT887Tlu6dGl5e3vLxcVFDg4PztELAODBZBiGMjIyVLp0zkH8vgwKFStWVP369RUdHa3Q0FBFR0erfv36dzztIEmOjo4qU6ZMIdQSAIDiIaeehOscDKuTEve4X375RePHj9elS5dUtmxZzZ07V7Vq1SrqagEAcE+5b4MCAAC4e/fl7ZEAACB/EBQAAIAlggIAALBEUAAAAJYICgAAwBJBIZeCgoIUHBysLl26qF27dhoyZIi+++67IqvP4sWLb/u46RsNHDhQv//+ewHXyH5vvvmmpk6dan7+8ssvVbduXR0/ftwcNmjQIH3yySc5Tv/HH38oICDA/Fy3bl1dvnz5lvH++c9/6vPPP8/HmheunNYrICBAf/zxR57md+nSJb377rt2jx8aGqqrV6/maVnFwYYNG9S1a1eFhoYqODhYr7127Ul8N67X+++/r/Pnz5vT7N27V7t27TI/nzlzRn369CnciheioKCg2z6N1l73+r52I6vtJjffublx4/9BcfuuloFcad26tfHTTz+Znzdt2mT4+voaBw8eLJL6eHt7GykpKXc1j4yMjHyqTe7s3r3bCA4ONj/PmTPH6N69u/Hvf//bMAzDyMzMNHx9fY2TJ0/mOP2pU6cMf39/83N+tEVxlNN6+fv7G6dOncrT/G5ut7wqqu0mN86cOWMEBAQYcXFxhmEYhs1mM77//vtbxrt5v160aJExZ86cQqtnUbt5/R90t9tuCup7pjj/H9yXT2YsTE8//bQOHz6sFStWaPbs2Zo5c6aOHDki6doRy8CBA/Xrr79qxIgRWr9+vTIzMxUQEKAhQ4ZowIAB+vzzz7Vt2zb94x//UJ8+fdSgQQMdPHhQCQkJ6tChg0aPHi1JeuuttxQdHS03Nzc5ODjogw8+0JtvvilJ6tmzpxwdHfXhhx9q+/bt+uCDD8x3VowbN05NmzaVdC2xLlu2TN7e3urTp4/q1aunQ4cOqVy5cpozZ45ee+0186iqadOmmjhxYoG2nY+Pj/744w+dO3dOlSpV0rfffqvhw4frs88+U69evXT06FG5u7tr1apV2rdvnzIyMlS+fHm98cYbqlatmuV8bTab5syZo3PnzmnOnDmaMmWKGjRooN69e2vx4sU6ceKEkpOTderUKT3yyCP65z//qZIlSyo5OVkTJ07U8ePHVbVqVVWtWlUVK1bUuHHjCrQd7lZQUJBCQkK0e/duJScn64UXXlDv3r1ls9kUHh6ub775Rq6uripVqpRWr16t8PBwJScnKzQ0VCVLltTq1av1r3/9S+vXr1dWVpbc3Nw0bdo01a9fX9K1Ho3vvvtOpUuXNpf1zTffyNvbWwMGDNCECROUmpoqm82mbt266aWXXiriFvmvc+fOydnZWR4eHpIkBwcHPfbYY5L+u14ffPCBEhISNHLkSLm5uWnu3LlavXq1bDabdu/erY4dOyokJER/+9vftHfvXnPaV155RVu2bFFSUpLGjh2r9u3bS5I2bdqkN998UyVKlFBwcLDefPNNs/3uJXPnzs1xv5s+fbqqVaumAQMGSJKOHj2qV155RRs3btSECRPui33NaruZPn26pNx954aGhmr37t06e/as+vfvr969e0uSYmJizPk1adIk2wuZbv6utvpd+Pnnn839r169evr99981ZMgQtW7dOn8bpKiTyr0mp9S3efNmo0OHDsa8efOMsWPHGjabzUhOTjZCQkKMr776yjAMw2jZsqVx5swZ47vvvjN69Ohh9O/f3zAMw3j99deN//znP4ZhGEbv3r2NUaNGGVlZWcalS5cMf39/48SJE8aFCxcMX19fIzU11TAMw0hOTjaP5m5Ot4mJiYbNZjMMwzB++eUXo0WLFjnWvXfv3sagQYPM+URERBivv/66OW5SUlL+NdpthIWFGevXrzfbKzMz02jXrp1hGIbx3nvvGWPGjDHOnz9vjv+f//zHePnllw3DyLlH4fz588aIESOMOXPmmO0wbtw448MPPzQM49qRYrt27YyLFy8aNpvN6Nevn/Hxxx8bhmEYs2fPNiZOnGgYhmFcuHDBaN26dbE4qrxTj0Lr1q2N8ePHG4ZhGGfPnjWaN29u/PDDD8b3339vBAcHG1lZWYZh/Pf/NKcehRvb+Ouvvza6d++e4/Jbt25tTJ061SybMWOGsWzZMvNzYW039srKyjKGDBli+Pv7GyNGjDAiIiKMxMREwzBuXa/b9SjktK1d36ZiYmKMwMBAwzCutf/1/dYwru1X90JPV07fa1b73c8//2y0bdvW3L8mTJhgvP/++4Zh3Pv72nX2bjeGcefv3OvrderUKaNRo0ZGSkqKkZaWZgQGBhrffPONYRiGsX79esPb29v8P7j5uzqn3wXDMIxu3boZa9euNQzDMA4fPmzUq1fP+OKLL/K9PehRyAfG/yXBPXv2aOLEiXJwcJC7u7s6duyoPXv2qFWrVnryySe1Z88e/fHHH+rRo4fee+89paena/fu3Ro4cKA5r+DgYPN9E7Vr19bvv/+u6tWr65FHHtHYsWMVGBiop556Su7uOb9C9tSpU3rttdd05swZOTs769y5czp79qwqV658y7idO3eWs/O1TaBhw4Z6//33NXfuXPn7+yswMLAAWupW/v7+2rt3r0qXLi1fX185OTmpRo0aOn78uPbt26enn35aO3bs0EcffaQrV64oMzPztvMbMGCAOnbseNuj2sDAQJUtW1aS9MQTT5jnAvfu3avJkydLkjw8PNS2bdt8WsuCceNLy5599llJUqVKlfTUU09p37596tatmzIzMzVp0iQFBATc9igjNjZW77zzji5evCgHBwf99ttvluN27drV/LtJkyaaP3++UlNTFRAQoCeffPKu1ys/OTo6asmSJTp27Ji+/fZbbd26VStWrFBUVNRdzzskJESS1KhRIyUkJCgtLU2HDh3SY489ppo1a0qS/va3v2n27Nl3vayiYLXf1a5dW9WrV9eOHTvUqFEjffHFF5owYUKO87hX97XcbDd3+s69vp08/PDDKlu2rE6fPq2MjAyVLFnSvMYqJCREU6ZMsaxPTr8LlSpV0rFjx9S587U39P71r39V3bp187spJHExY744cuSI6tSpc9txnnzySX3zzTf65ptv1LRpUzVs2FDr16+XYRiqXr26OZ6bm5v59/U3Xzo5Oek///mPevfurdOnT+uZZ57Rjz/+mONyXn31VYWFhWn9+vVas2aNnJycLN9BXqpUKfNvHx8frVmzRg0aNFBkZKT69u2bmybIs4CAAO3bt0/ffvutmjRpIunaj8+ePXu0f/9+Va9eXbNnz9Y//vEPRUdH64033rjthUQBAQHauXOnUlNTLcfJqY2LswoVKigpKcn8nJmZqZSUlDu+5KxMmTJav369QkJC9NNPP6ljx446e/bsLeOlp6dr1KhRmjhxoqKjo80Qa+XG7aZ9+/ZauXKlHnnkEb377rsaM2ZM7lewEHh7e6tXr16KiIhQmTJltG/fvrue5/XtyMnJSZLuGGLvJX/++edt97s+ffpo1apV+vTTT/X0009bvkjvXtvXbmbPdnOn71x72+B2byu+3TwK4y3HBIW7tHXrVq1atUr9+/dX06ZN9emnn8owDKWkpOjzzz9Xs2bNJF07579z505dvHhRDz30kJo1a6bFixeb57JuJyUlRYmJifL399fIkSPl7e1t3hlQunRppaSkmOMmJyfr4YcfliR9+umndl+de+rUKbMXZMKECfr+++9ls9ly2xy55uPjoz///FObN2+Wv7+/JMnPz08rV65U2bJlVa5cObm4uKhy5cqy2WxavXr1bec3fPhwNWvWTC+99FK2drGHv7+/IiMjJV27M2Dbtm15W6l81qxZM3388cfm548//lgNGzZUyZIlzWFr1qyRJCUmJmr79u0KCAhQYmKiUlNT1aJFC40ePVplypQx/5+vXr1q/rClp6crMzPTfA37Rx99ZHfdTp48qcqVK+uZZ57RsGHDzOtzioszZ87owIED5ufTp08rMTHR3EeuK126tJKTk83P7u7u2T7bq2HDhjp69Kh55Hz9/+Vek5KSctv9rlWrVjpx4oQiIiIUFhaW6/kX133tutttN/nxnVurVi1dvXpVMTExkqSNGzfq0qVLuaqju7u76tSpo+joaEnS999/ny93ruSEUw95MHLkSLm6uio1NVW1a9fW8uXL1bBhQ/3lL3/RjBkzzK6gLl26qGXLlpKkhx56yOxel671MMTFxdnVVZuSkqIRI0bo6tWrMgxDjz32mJ5++mlJUv/+/dW3b1+VKFFCH374oSZMmKChQ4eqXLlyatGihXkxzp3s27dP77//vhwdHWWz2TR9+nQ5OhZ8jnRzc1PDhg115swZVa1aVdK1LrQzZ84oODhYdevWVXBwsEJCQlS+fHm1atXK3Lms/P3vf1eJEiX04osv6r333rO7LsOGDdOECRMUHBysypUrq0GDBpaneArTpEmTNGvWLHXu3FmOjo7y9PTUvHnzso1Tvnx5PfPMM0pOTtagQYNUt25dff/993r99deVmZmprKwstWzZUo0aNZKjo6M6d+6szp07q1y5clq9erVGjhypZ599Vh4eHuZFefbYsGGDoqKi5OLiIgcHhwK/ADa3MjMztXjxYv35558qUaKEbDabXn75ZfOCxuv69u2riRMnqkSJEvrHP/6htm3bau3atQoNDTUvZrRHpUqVNG3aNA0cOFAlS5bUU089JRcXl2yhrrjq16+f2Tsi6bb7naOjo7p27aodO3aoXr16uV5Wcd3XrrvddpMf37murq5auHBhtosZvby8cl3PuXPnauLEiVq+fLm8vb3l7e1t2btzN3h7JPB/MjIyZLPZ5ObmppSUFD3//POaMGGC2StUXN14hTSKXkpKivmj9+mnn+p///d/tWrVqiKuVf7r16+fnnvuOXXo0CHX096r+1pxc/nyZZUqVUoODg76+eef1adPH23cuFHlypXL1+XQowD8n0uXLmngwIHKyspSWlqaOnXqxBcXcu3DDz/Uxo0blZWVpXLlymnmzJlFXaV8deTIEb3yyit67LHHctX7dCP2tfxx4MABzZs3z7ygfsaMGfkeEiR6FAAAwG1wMSMAALBEUAAAAJYICgAAwBJBAYClxYsXm8+VL86CgoK0e/fuQp8WeBAQFIAHXFRUlJ555hn5+PgoMDBQAwYMuOOzKgpK3bp1dfLkySJZNoCccXsk8ACLiIjQ8uXLNX36dAUGBsrFxUU7d+7Utm3b5OfnV9TVA1AM0KMAPKCSk5O1aNEiTZkyRU8//bRKlSolFxcXBQUFWb7ud+TIkWrevLl8fX3Vq1cv81HikrR9+3aFhITIx8dHLVq00IoVKyRde6z0oEGD5OfnJ39/f4WFheX68eC///67+vbtq4CAAAUEBOi111675ZG3R44cUUhIiJo0aaIJEyZke97+l19+qdDQUPn5+alnz56W70o5fPiwnnnmGTVu3FjNmjW7Z1/oBOQnggLwgDpw4IDS0tLUrl07u6dp2bKlNm3apD179uixxx7Ldv3CpEmTFB4ergMHDig6Otp8PHlERISqVq2qPXv26Ouvv9arr76a6xfZGIahQYMGaefOndqwYYNOnz6txYsXZxsnKipKK1as0JYtW3TixAktWbJEknT06FFNnDhR4eHh2rt3r3r06KGhQ4fm+Ez+WbNmqW/fvvruu++0ZcuWPD11ELjfEBSAB1RSUpLKly9vvmrcHs8++6zc3d3l6uqqESNG6McffzRfnuTs7Kyff/5ZKSkpKleunB5//HFz+NmzZxUXFycXFxf5+fnlOijUqFFDzZs3l6urqypUqKB+/frp22+/zTZOr1695OnpKQ8PDw0ZMkTr16+XdO0lWj169FDDhg3l5OSkbt26ycXFRQcPHrxlOc7Ozvr999+VmJio0qVLq1GjRrmqJ3A/IigADygPDw9duHDB7tcjZ2VlacGCBWrbtq0aN26soKAgSdKFCxckSYsWLdL27dvVunVr9e7d23z73ksvvaQaNWqof//+atOmjZYvX57rup47d06vvPKKWrRoocaNG2vMmDHmcq+7/vZLSfLy8lJCQoIkKS4uThEREfLz8zP/nT592iy/0axZs/Tbb7+pQ4cO+tvf/qYvv/wy13UF7jdczAg8oHx8fOTq6qqtW7cqODj4juNHRUVp27ZtioiI0MMPP6zk5GQ1adLEfM78E088oaVLlyojI0MrV67Uyy+/rO3bt8vd3V3jx4/X+PHjdezYMb3wwgv661//atcr1q9buHChHBwcFBUVJQ8PD23dulXh4eHZxomPjzf/jouLU5UqVSRdCxCDBw/WkCFD7ricmjVrauHChbLZbNq8ebNGjhypvXv3qlSpUnbXFbjf0KMAPKDKlCmjkSNHKjw8XFu3blVqaqoyMjK0ffv2W15jLV17U52rq6vKly+v1NRULVy40CxLT0/XunXrlJycLBcXF5UuXdp8TfmXX36pkydPyjAMlSlTRk5OTrc99ZCRkaG0tDTzX1ZWlvmWvDJlyujMmTM5vj78o48+0unTp5WUlKRly5aZr4bu3r27Vq9erUOHDskwDF25ckVfffWVUlJSbplHZGSkEhMT5ejoqLJly0pSobxuHSjO6FEAHmD9+/dXpUqVtGTJEo0ePVqlS5fW448/rsGDB98ybteuXbVr1y61aNFCHh4eGjVqVLbXJ0dGRmrGjBnKysrSo48+qvnz50uSTp48qRkzZigxMVFly5bV888/b17omJOOHTtm+zxz5kwNHz5c48aNk5+fnx555BGFhobq/fffzzZep06d1L9/fyUkJKhNmzZmD8Jf//pXzZgxQ+Hh4Tp58qRKlCihxo0b53j7586dOzVnzhxdvXpVXl5eevPNN1WiRAm72xO4H/H2SAAAYIk+NQAAYImgAAAALBEUAACAJYICAACwRFAAAACWCAoAAMASQQEAAFgiKAAAAEsEBQAAYOn/AzXy0I+vzm4qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Checking class balance\n",
    "class_counts = df_Smoted['Label'].value_counts()\n",
    "print(\"Class Counts:\\n\", class_counts)\n",
    "\n",
    "# Plotting class balance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.countplot(x='Label', data=df_Smoted, palette=\"Set2\")\n",
    "plt.title('Class Distribution After SMOTE Balancing')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# # Displaying percentages on top of the bars\n",
    "# total = len(df_filtred['Label'])\n",
    "# for i, count in enumerate(class_counts):\n",
    "#     plt.text(i, count + 0.1, f'{count/total*100:.2f}%', ha='center')\n",
    "\n",
    "# Save the plot to a file if needed\n",
    "# plt.savefig('class_balance_plot.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de0bd882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1_Ax</th>\n",
       "      <th>S1_Ay</th>\n",
       "      <th>S1_Az</th>\n",
       "      <th>S1_Gx</th>\n",
       "      <th>S1_Gy</th>\n",
       "      <th>S1_Gz</th>\n",
       "      <th>S2_Ax</th>\n",
       "      <th>S2_Ay</th>\n",
       "      <th>S2_Az</th>\n",
       "      <th>S2_Gx</th>\n",
       "      <th>S2_Gy</th>\n",
       "      <th>S2_Gz</th>\n",
       "      <th>S3_Ax</th>\n",
       "      <th>S3_Ay</th>\n",
       "      <th>S3_Az</th>\n",
       "      <th>S3_Gx</th>\n",
       "      <th>S3_Gy</th>\n",
       "      <th>S3_Gz</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-84.222490</td>\n",
       "      <td>-994.627346</td>\n",
       "      <td>8.055153</td>\n",
       "      <td>-0.370396</td>\n",
       "      <td>-2.620791</td>\n",
       "      <td>1.649596</td>\n",
       "      <td>311.291489</td>\n",
       "      <td>-1061.332673</td>\n",
       "      <td>81.294603</td>\n",
       "      <td>2.077435</td>\n",
       "      <td>-3.234044</td>\n",
       "      <td>-4.329407</td>\n",
       "      <td>-68.121248</td>\n",
       "      <td>-970.461276</td>\n",
       "      <td>150.138268</td>\n",
       "      <td>1.829730</td>\n",
       "      <td>0.240081</td>\n",
       "      <td>0.610366</td>\n",
       "      <td>Downstairs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-88.069874</td>\n",
       "      <td>-998.773910</td>\n",
       "      <td>11.651440</td>\n",
       "      <td>-0.282880</td>\n",
       "      <td>-3.161370</td>\n",
       "      <td>0.810362</td>\n",
       "      <td>301.127326</td>\n",
       "      <td>-1027.592784</td>\n",
       "      <td>86.576920</td>\n",
       "      <td>6.452058</td>\n",
       "      <td>2.962058</td>\n",
       "      <td>-3.769370</td>\n",
       "      <td>-70.387323</td>\n",
       "      <td>-977.643665</td>\n",
       "      <td>146.687971</td>\n",
       "      <td>0.477777</td>\n",
       "      <td>-0.317638</td>\n",
       "      <td>0.282808</td>\n",
       "      <td>Downstairs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       S1_Ax       S1_Ay      S1_Az     S1_Gx     S1_Gy     S1_Gz       S2_Ax  \\\n",
       "0 -84.222490 -994.627346   8.055153 -0.370396 -2.620791  1.649596  311.291489   \n",
       "1 -88.069874 -998.773910  11.651440 -0.282880 -3.161370  0.810362  301.127326   \n",
       "\n",
       "         S2_Ay      S2_Az     S2_Gx     S2_Gy     S2_Gz      S3_Ax  \\\n",
       "0 -1061.332673  81.294603  2.077435 -3.234044 -4.329407 -68.121248   \n",
       "1 -1027.592784  86.576920  6.452058  2.962058 -3.769370 -70.387323   \n",
       "\n",
       "        S3_Ay       S3_Az     S3_Gx     S3_Gy     S3_Gz       Label  Label_id  \n",
       "0 -970.461276  150.138268  1.829730  0.240081  0.610366  Downstairs         0  \n",
       "1 -977.643665  146.687971  0.477777 -0.317638  0.282808  Downstairs         0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Smoted['Label_id']=df_Smoted['Label']\n",
    "dff=df_Smoted.replace({'Label_id': {'Downstairs':0,'Walking':1,'Upstairs':2,\n",
    "                        'Sitting':3,'Laying':4,'Standing':5}})\n",
    "dff.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79320b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108170, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1_Ax</th>\n",
       "      <th>S1_Ay</th>\n",
       "      <th>S1_Az</th>\n",
       "      <th>S1_Gx</th>\n",
       "      <th>S1_Gy</th>\n",
       "      <th>S1_Gz</th>\n",
       "      <th>S2_Ax</th>\n",
       "      <th>S2_Ay</th>\n",
       "      <th>S2_Az</th>\n",
       "      <th>S2_Gx</th>\n",
       "      <th>S2_Gy</th>\n",
       "      <th>S2_Gz</th>\n",
       "      <th>S3_Ax</th>\n",
       "      <th>S3_Ay</th>\n",
       "      <th>S3_Az</th>\n",
       "      <th>S3_Gx</th>\n",
       "      <th>S3_Gy</th>\n",
       "      <th>S3_Gz</th>\n",
       "      <th>Label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108168</th>\n",
       "      <td>-1.184801</td>\n",
       "      <td>-1.246834</td>\n",
       "      <td>1.052031</td>\n",
       "      <td>-1.358904</td>\n",
       "      <td>1.442018</td>\n",
       "      <td>0.213337</td>\n",
       "      <td>-0.374825</td>\n",
       "      <td>0.984964</td>\n",
       "      <td>0.103477</td>\n",
       "      <td>-0.647672</td>\n",
       "      <td>0.728023</td>\n",
       "      <td>0.554009</td>\n",
       "      <td>-0.495231</td>\n",
       "      <td>-0.095276</td>\n",
       "      <td>0.177837</td>\n",
       "      <td>0.934893</td>\n",
       "      <td>3.810924</td>\n",
       "      <td>-1.627844</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108169</th>\n",
       "      <td>-0.948608</td>\n",
       "      <td>-2.459766</td>\n",
       "      <td>0.808399</td>\n",
       "      <td>-2.407089</td>\n",
       "      <td>1.100033</td>\n",
       "      <td>0.209530</td>\n",
       "      <td>-0.625947</td>\n",
       "      <td>0.657764</td>\n",
       "      <td>0.264402</td>\n",
       "      <td>-0.508701</td>\n",
       "      <td>1.039492</td>\n",
       "      <td>0.488135</td>\n",
       "      <td>-0.641922</td>\n",
       "      <td>-0.120628</td>\n",
       "      <td>0.178026</td>\n",
       "      <td>0.853266</td>\n",
       "      <td>3.767479</td>\n",
       "      <td>-1.420029</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           S1_Ax     S1_Ay     S1_Az     S1_Gx     S1_Gy     S1_Gz     S2_Ax  \\\n",
       "108168 -1.184801 -1.246834  1.052031 -1.358904  1.442018  0.213337 -0.374825   \n",
       "108169 -0.948608 -2.459766  0.808399 -2.407089  1.100033  0.209530 -0.625947   \n",
       "\n",
       "           S2_Ay     S2_Az     S2_Gx     S2_Gy     S2_Gz     S3_Ax     S3_Ay  \\\n",
       "108168  0.984964  0.103477 -0.647672  0.728023  0.554009 -0.495231 -0.095276   \n",
       "108169  0.657764  0.264402 -0.508701  1.039492  0.488135 -0.641922 -0.120628   \n",
       "\n",
       "           S3_Az     S3_Gx     S3_Gy     S3_Gz  Label_id  \n",
       "108168  0.177837  0.934893  3.810924 -1.627844         5  \n",
       "108169  0.178026  0.853266  3.767479 -1.420029         5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding\n",
    "df_filtred['Label_id']=df_filtred['Label']\n",
    "dff=df_filtred.replace({'Label_id': {'Downstairs':0,'Walking':1,'Upstairs':2,\n",
    "                        'Sitting':3,'Laying':4,'Standing':5}})\n",
    "## Normalize/Standardize data\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "X = dff[['S1_Ax', 'S1_Ay', 'S1_Az', 'S1_Gx', 'S1_Gy','S1_Gz', 'S2_Ax', 'S2_Ay', 'S2_Az', 'S2_Gx', 'S2_Gy', 'S2_Gz', 'S3_Ax',\n",
    "       'S3_Ay', 'S3_Az', 'S3_Gx', 'S3_Gy', 'S3_Gz']]\n",
    "y = dff['Label_id']\n",
    "scaler = StandardScaler()\n",
    "dx = scaler.fit_transform(X)\n",
    "\n",
    "df_scaled = pd.DataFrame(data = dx, columns = X.columns)\n",
    "df_scaled['Label_id'] = y.values\n",
    "\n",
    "print(df_scaled.shape)\n",
    "df_scaled.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b623d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Segmentation (window Preparation)\n",
    "import scipy.stats as stats\n",
    "Fs = 100\n",
    "segment_size = 500 # fs*3 # window size=n_time steps=frame size\n",
    "step_size = 50  #  Fs/2 # step size is related to window overlap\n",
    "n_features = 18\n",
    "def get_segments(df, segment_size, step_size):\n",
    "\n",
    "    segments = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, len(df) - segment_size - 1, step_size):\n",
    "        S1Ax = df_scaled['S1_Ax'].values[i: i + segment_size]\n",
    "        S1Ay = df_scaled['S1_Ay'].values[i: i + segment_size]\n",
    "        S1Az = df_scaled['S1_Az'].values[i: i + segment_size]\n",
    "        S1Gx = df_scaled['S1_Gx'].values[i: i + segment_size]\n",
    "        S1Gy = df_scaled['S1_Gy'].values[i: i + segment_size]\n",
    "        S1Gz = df_scaled['S1_Gz'].values[i: i + segment_size]\n",
    "        \n",
    "        S2Ax = df_scaled['S2_Ax'].values[i: i + segment_size]\n",
    "        S2Ay = df_scaled['S2_Ay'].values[i: i + segment_size]\n",
    "        S2Az = df_scaled['S2_Az'].values[i: i + segment_size]\n",
    "        S2Gx = df_scaled['S2_Gx'].values[i: i + segment_size]\n",
    "        S2Gy = df_scaled['S2_Gy'].values[i: i + segment_size]\n",
    "        S2Gz = df_scaled['S2_Gz'].values[i: i + segment_size]\n",
    "        \n",
    "        \n",
    "        S3Ax = df_scaled['S3_Ax'].values[i: i + segment_size]\n",
    "        S3Ay = df_scaled['S3_Ay'].values[i: i + segment_size]\n",
    "        S3Az = df_scaled['S3_Az'].values[i: i + segment_size]\n",
    "        S3Gx = df_scaled['S3_Gx'].values[i: i + segment_size]\n",
    "        S3Gy = df_scaled['S3_Gy'].values[i: i + segment_size]\n",
    "        S3Gz = df_scaled['S3_Gz'].values[i: i + segment_size]\n",
    "        \n",
    "          # Retrieve the most often used label in this segment\n",
    "        # label = stats.mode(df_scaled['Label_id'][i: i + segment_size])[0][0] ## [0][0] shows the current sequence\n",
    "        label = np.unique(df_scaled['Label_id'][i: i + segment_size])[0]\n",
    "\n",
    "        #We used the dstack() to ensure that each array is stacked in such a way that\n",
    "        #the features are separated in the third dimension, as we would prefer.\n",
    "        segments.append(np.dstack([S1Ax, S1Ay, S1Az,S1Gx,S1Gy,S1Gz,S2Ax,S2Ay,S2Az, S2Gx,S2Gy,S2Gz,S3Ax,S3Ay,S3Az,S3Gx,S3Gy,S3Gz]))\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    segments=np.asarray(segments, dtype= np.float32).reshape(-1, segment_size, n_features)\n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "        \n",
    "    return segments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f7b9199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_segments(df_scaled, segment_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac4ad83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2154, 500, 18), (2154, 6), 2154)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape, y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7657368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data into time steps of sub-sequences\n",
    "\n",
    "n_steps, n_length = 10, 50\n",
    "df_X = X.reshape((X.shape[0], n_steps, n_length, n_features))\n",
    "n_outputs = y.shape[1] #n_outputs= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa2e312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split data into training set and test set\n",
    "X_train_main, X_test, y_train_main, y_test = train_test_split(df_X, y,test_size=0.20, random_state=42)\n",
    "\n",
    "# split training set into training and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_main,y_train_main,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21e41fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "053dd298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 11:37:45.106752: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 11:37:45.836026: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 11:37:48.084579: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 11:37:48.094094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 11:37:48.481867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 11:37:49.457322: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 11:37:49.464912: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 11:38:02.360981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "# from keras.layers.convolutional import Conv1D\n",
    "# from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Conv1D  # Updated import\n",
    "from keras.layers import MaxPooling1D  # Updated import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b12d79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate, Input, Dense, TimeDistributed, Conv1D, Dropout, MaxPooling2D, Flatten, LSTM\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, GlobalAveragePooling3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d446004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 10, 50, 18)]         0         []                            \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 10, 50, 18)           36        ['input_4[0][0]']             \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (M  (None, 10, 50, 18)           60018     ['layer_normalization_16[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 10, 50, 18)           0         ['multi_head_attention_13[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " time_distributed_49 (TimeD  (None, 10, 50, 100)          1900      ['input_4[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenat  (None, 10, 50, 118)          0         ['dropout_30[0][0]',          \n",
      " e)                                                                  'time_distributed_49[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_50 (TimeD  (None, 10, 50, 500)          59500     ['concatenate_16[0][0]']      \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 10, 50, 4)            2004      ['time_distributed_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 10, 50, 4)            0         ['conv1d_21[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, 10, 50, 4)            0         ['dropout_31[0][0]',          \n",
      " FOpLambda)                                                          'dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 10, 50, 4)            8         ['tf.__operators__.add_13[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (M  (None, 10, 50, 4)            15204     ['layer_normalization_17[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)        (None, 10, 50, 4)            0         ['multi_head_attention_14[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " time_distributed_51 (TimeD  (None, 10, 50, 100)          1900      ['input_4[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenat  (None, 10, 50, 104)          0         ['dropout_32[0][0]',          \n",
      " e)                                                                  'time_distributed_51[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_52 (TimeD  (None, 10, 50, 500)          52500     ['concatenate_17[0][0]']      \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 10, 50, 4)            2004      ['time_distributed_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)        (None, 10, 50, 4)            0         ['conv1d_22[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (None, 10, 50, 4)            0         ['dropout_33[0][0]',          \n",
      " FOpLambda)                                                          'dropout_33[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, 10, 50, 4)            8         ['tf.__operators__.add_14[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (M  (None, 10, 50, 4)            15204     ['layer_normalization_18[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)        (None, 10, 50, 4)            0         ['multi_head_attention_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " time_distributed_53 (TimeD  (None, 10, 50, 100)          1900      ['input_4[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenat  (None, 10, 50, 104)          0         ['dropout_34[0][0]',          \n",
      " e)                                                                  'time_distributed_53[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_54 (TimeD  (None, 10, 50, 500)          52500     ['concatenate_18[0][0]']      \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 10, 50, 4)            2004      ['time_distributed_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)        (None, 10, 50, 4)            0         ['conv1d_23[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.__operators__.add_15 (T  (None, 10, 50, 4)            0         ['dropout_35[0][0]',          \n",
      " FOpLambda)                                                          'dropout_35[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, 10, 50, 4)            8         ['tf.__operators__.add_15[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (M  (None, 10, 50, 4)            15204     ['layer_normalization_19[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)        (None, 10, 50, 4)            0         ['multi_head_attention_16[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " time_distributed_55 (TimeD  (None, 10, 50, 100)          1900      ['input_4[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenat  (None, 10, 50, 104)          0         ['dropout_36[0][0]',          \n",
      " e)                                                                  'time_distributed_55[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_56 (TimeD  (None, 10, 50, 500)          52500     ['concatenate_19[0][0]']      \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_44 (TimeD  (None, 10, 46, 32)           2912      ['input_4[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)          (None, 10, 50, 4)            2004      ['time_distributed_56[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_45 (TimeD  (None, 10, 40, 16)           3600      ['time_distributed_44[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 10, 50, 4)            0         ['conv1d_24[0][0]']           \n",
      "                                                                                                  \n",
      " time_distributed_46 (TimeD  (None, 10, 40, 16)           0         ['time_distributed_45[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (None, 10, 50, 4)            0         ['dropout_37[0][0]',          \n",
      " FOpLambda)                                                          'dropout_37[0][0]']          \n",
      "                                                                                                  \n",
      " time_distributed_47 (TimeD  (None, 10, 20, 16)           0         ['time_distributed_46[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " layer_normalization_20 (La  (None, 10, 50, 4)            8         ['tf.__operators__.add_16[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " time_distributed_48 (TimeD  (None, 10, 320)              0         ['time_distributed_47[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_57 (TimeD  (None, 10, 50, 18)           90        ['layer_normalization_20[0][0]\n",
      " istributed)                                                        ']                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 100)                  168400    ['time_distributed_48[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)         (None, 9000)                 0         ['time_distributed_57[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenat  (None, 9100)                 0         ['lstm_3[0][0]',              \n",
      " e)                                                                  'flatten_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_41 (Dense)            (None, 6)                    54606     ['concatenate_20[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 567922 (2.17 MB)\n",
      "Trainable params: 567922 (2.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Concatenate, Input, Dense, TimeDistributed, Conv1D, Dropout, MaxPooling2D, Flatten, LSTM\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, GlobalAveragePooling3D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "\n",
    "def create_combined_model(input_shape, n_outputs=n_outputs):\n",
    "    # Shared Input Layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # CNN-LSTM Branch\n",
    "    cnn_lstm_branch = TimeDistributed(Conv1D(filters=32, kernel_size=5, activation='relu'))(input_layer)\n",
    "    cnn_lstm_branch = TimeDistributed(Conv1D(filters=16, kernel_size=7, activation='relu'))(cnn_lstm_branch)\n",
    "    cnn_lstm_branch = TimeDistributed(Dropout(0.5))(cnn_lstm_branch)\n",
    "    cnn_lstm_branch = TimeDistributed(MaxPooling1D(pool_size=2))(cnn_lstm_branch)\n",
    "    cnn_lstm_branch = TimeDistributed(Flatten())(cnn_lstm_branch)\n",
    "    cnn_lstm_branch = LSTM(100, dropout=0.5, recurrent_dropout=0.5, kernel_regularizer=l2(0.01))(cnn_lstm_branch)\n",
    "\n",
    "    # Transformer Encoder Branch\n",
    "    transformer_branch = LayerNormalization(epsilon=1e-6)(input_layer)\n",
    "\n",
    "    # Parameters for Transformer\n",
    "    num_transformer_blocks = 4\n",
    "    d_model = 100\n",
    "    num_heads = 8\n",
    "    ffn_units = 500\n",
    "    ff_dim = 4\n",
    "    mlp_dropout = 0\n",
    "    dropout_rate = 0.15\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        # Multi-Head Self-Attention\n",
    "        transformer_branch = MultiHeadAttention(key_dim=d_model, num_heads=num_heads, dropout=dropout_rate)(transformer_branch, transformer_branch)\n",
    "        transformer_branch = Dropout(dropout_rate)(transformer_branch)\n",
    "\n",
    "        # Project input_layer to the same dimension as transformer_branch\n",
    "        projection_layer = TimeDistributed(Dense(d_model))(input_layer)\n",
    "\n",
    "        # Concatenate transformer_branch and projection_layer along the last axis\n",
    "        transformer_branch = Concatenate(axis=-1)([transformer_branch, projection_layer])\n",
    "\n",
    "        # Feed-Forward Part\n",
    "        transformer_branch = TimeDistributed(Dense(ffn_units, activation=\"relu\"))(transformer_branch)\n",
    "        transformer_branch = Conv1D(filters=ff_dim, kernel_size=1, activation='relu')(transformer_branch)\n",
    "        transformer_branch = Dropout(mlp_dropout)(transformer_branch)\n",
    "        transformer_branch = LayerNormalization(epsilon=1e-6)(transformer_branch + transformer_branch)\n",
    "\n",
    "\n",
    "    transformer_branch = TimeDistributed(Dense(18, activation=\"relu\"))(transformer_branch)\n",
    "\n",
    "    # Combine the branches\n",
    "    merged = Concatenate(axis=-1)([cnn_lstm_branch, Flatten()(transformer_branch)])\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = Dense(n_outputs, activation='softmax')(merged)\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model with the desired optimizer, loss, and metrics\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Assuming your segment shape is (10, 50, 18)\n",
    "input_shape = (10, 50, 18)\n",
    "n_outputs = 6  # Replace with your actual number of output classes\n",
    "combined_model = create_combined_model(input_shape, n_outputs)\n",
    "combined_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3040b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "44/44 [==============================] - 100s 2s/step - loss: 3.5746 - accuracy: 0.3657 - val_loss: 2.1154 - val_accuracy: 0.4377\n",
      "Epoch 2/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 1.4755 - accuracy: 0.5914 - val_loss: 1.1706 - val_accuracy: 0.6087\n",
      "Epoch 3/20\n",
      "44/44 [==============================] - 91s 2s/step - loss: 0.8764 - accuracy: 0.7119 - val_loss: 1.1554 - val_accuracy: 0.5826\n",
      "Epoch 4/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.8775 - accuracy: 0.7032 - val_loss: 0.9522 - val_accuracy: 0.6725\n",
      "Epoch 5/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.5316 - accuracy: 0.8389 - val_loss: 0.7257 - val_accuracy: 0.7913\n",
      "Epoch 6/20\n",
      "44/44 [==============================] - 94s 2s/step - loss: 0.3912 - accuracy: 0.8948 - val_loss: 0.7179 - val_accuracy: 0.7913\n",
      "Epoch 7/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.3156 - accuracy: 0.9202 - val_loss: 0.7014 - val_accuracy: 0.7507\n",
      "Epoch 8/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.2798 - accuracy: 0.9245 - val_loss: 0.7863 - val_accuracy: 0.7797\n",
      "Epoch 9/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.2579 - accuracy: 0.9390 - val_loss: 0.7929 - val_accuracy: 0.7710\n",
      "Epoch 10/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.2841 - accuracy: 0.9180 - val_loss: 0.7087 - val_accuracy: 0.8029\n",
      "Epoch 11/20\n",
      "44/44 [==============================] - 91s 2s/step - loss: 0.2754 - accuracy: 0.9238 - val_loss: 0.6893 - val_accuracy: 0.7797\n",
      "Epoch 12/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.3011 - accuracy: 0.9165 - val_loss: 0.7589 - val_accuracy: 0.7594\n",
      "Epoch 13/20\n",
      "44/44 [==============================] - 92s 2s/step - loss: 0.2032 - accuracy: 0.9572 - val_loss: 0.5996 - val_accuracy: 0.8319\n",
      "Epoch 14/20\n",
      "13/44 [=======>......................] - ETA: 1:00 - loss: 0.1361 - accuracy: 0.9856"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training the combined model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     11\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m combined_model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training the combined model\n",
    "history = combined_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = combined_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff17d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epochs):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, epochs+1)\n",
    "  plt.plot(epoch_range, history.history['accuracy'])\n",
    "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d32e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learningCurve(history, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
